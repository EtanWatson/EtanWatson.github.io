<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="EWSUN" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="有所舍，有所爱，做一个感性的码农">
<meta property="og:type" content="website">
<meta property="og:title" content="EWSUN">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="EWSUN">
<meta property="og:description" content="有所舍，有所爱，做一个感性的码农">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="EWSUN">
<meta name="twitter:description" content="有所舍，有所爱，做一个感性的码农">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/3/"/>





  <title>EWSUN</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">EWSUN</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br />
            
            日程表
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            站点地图
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/09/二分查找/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="EtanWatson">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EWSUN">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/09/二分查找/" itemprop="url">二分查找</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-09T08:27:35+08:00">
                2017-10-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/algorithm/" itemprop="url" rel="index">
                    <span itemprop="name">algorithm</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h1><h2 id="二分查找的工作原理"><a href="#二分查找的工作原理" class="headerlink" title="二分查找的工作原理"></a>二分查找的工作原理</h2><p>你的目标是以最少的次数猜到这个数字。你每次猜测后，我会说小了、大了或对了。 假设你从1开始依次往上猜，猜测过程会是这样。（一种糟糕的猜数法）<br>一种好的猜数法，从50开始。如果小了，接下来猜75……,不管是什么数，在第七次一定能猜到<br>一般而言，对于包含n个元素的列表，用二分查找最多需要log2n步，而简单查找最多需要n步。<br>注：仅当列表有序的时候，二分查找才管用</p>
<h3 id="代码实现（python-2-7）"><a href="#代码实现（python-2-7）" class="headerlink" title="代码实现（python 2.7）"></a>代码实现（python 2.7）</h3><pre><code class="bash"><span class="comment">#范围</span>
low = 0
heigh = len(list) - 1
<span class="comment">#每次检查的中间的元素</span>
mid = (low + heigh) / 2
guess = list[mid]
<span class="comment">#如果数猜小了，就相应的修改low</span>
<span class="keyword">if</span> guess &lt; item:
    low = mid + 1
<span class="comment">#如果数猜大了，就修改heigh</span>
<span class="comment">#完整代码如下</span>
def binary_search(list, item)
    low = 0
    heigh = len(list) - 1

    <span class="keyword">while</span> low &lt;= heigh:
        mid = (low + heigh)
        guess = list[mid]
        <span class="keyword">if</span> guess == item:     <span class="comment">#放在第一个判断可以减少下面的操作</span>
            <span class="built_in">return</span> mid
        <span class="keyword">if</span> guess &lt; item:
            low = mid + 1
        <span class="keyword">else</span>:
            heigh = mid - 1
    <span class="built_in">return</span> None
</code></pre>
<h2 id="运行时间"><a href="#运行时间" class="headerlink" title="运行时间"></a>运行时间</h2><p>最多需要猜测的次数与列表长度相同，这被称为线性 时间(linear time)。<br>二分查找的运行时间为对数时间(或log时间)</p>
<h2 id="大O表示法"><a href="#大O表示法" class="headerlink" title="大O表示法"></a>大O表示法</h2><h3 id="运算时间以不同的速度增加"><a href="#运算时间以不同的速度增加" class="headerlink" title="运算时间以不同的速度增加"></a>运算时间以不同的速度增加</h3><pre><code>简单查找          二分查找
</code></pre><p>100个元素                100毫秒          7毫秒<br>10000个元素            10秒        14毫秒<br>1000000000个元素        11天        32毫秒<br>注：以上表示的是至多查找时间<br>有鉴于此，仅知道算法 需要多长时间才能运行完毕还不够，还需知道运行时间如何随列表增长 而增加。这正是大O表示法的用武之地。</p>
<h3 id="理解不同的大O运行时间"><a href="#理解不同的大O运行时间" class="headerlink" title="理解不同的大O运行时间"></a>理解不同的大O运行时间</h3><p>O(n) 与 O（log n）  注：非特殊说明，均以2为底</p>
<h3 id="大O表示法指出了最糟糕情况下的运行时间"><a href="#大O表示法指出了最糟糕情况下的运行时间" class="headerlink" title="大O表示法指出了最糟糕情况下的运行时间"></a>大O表示法指出了最糟糕情况下的运行时间</h3><h3 id="一些常见的大O运行时间"><a href="#一些常见的大O运行时间" class="headerlink" title="一些常见的大O运行时间"></a>一些常见的大O运行时间</h3><p>O(log n)，也叫对数时间，这样的算法包括二分查找。<br>O(n)，也叫线性时间，这样的算法包括简单查找。<br>O(n*log n)，这样的算法包括第4章将介绍的快速排序——一种速度较快的排序算法<br>O(n^2)，这样的算法包括第2章将介绍的选择排序——一种速度较慢的排序算法。<br>O(n!)，这样的算法包括接下来将介绍的旅行商问题的解决方案——一种非常慢的算法。</p>
<p>主要启示：<br>算法的速度并非时间，二十操作数的增速<br>谈论算法的速度时，我们说的是随着输入增加，其运行时间将以什么样的速度增加。<br>算法的运行时间用大O表示法表示<br>O(logn)比O(n)快，当需要搜索的元素越多时，前者比后者快的越多</p>
<h3 id="旅行商问题"><a href="#旅行商问题" class="headerlink" title="旅行商问题"></a>旅行商问题</h3><p>有一位旅行商。 他需要前往5个城市。<br>这位旅行商(姑且称之为Opus吧)要前往这5个城市，同时要确保旅程最短。为此，可考虑 前往这些城市的各种可能顺序。<br>对于每种顺序，他都计算总旅程，再挑选出旅程最短的路线。5个城市有120种不同的排列方 式。因此，在涉及5个城市时，解决这个问题需要执行120次操作。涉及6个城市时，需要执行720 次操作(有720种不同的排列方式)。涉及7个城市时，需要执行5040次操作!故，可以推出，涉及n个城市时，需要执行n!(n的阶乘)次操作才能计算出结果。如果涉及的城市 数超过100，根本就不能在合理的时间内计算出结果——等你计算出结果，太阳都没了。O(n!),由于目前还没有更巧妙的算法，所以我们能做的只是去找出近似答案。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>二分查找的速度比简单查找快得多。<br>O(log n)比O(n)快。需要搜索的元素越多，前者比后者就快得越多。  算法运行时间并不以秒为单位。<br>算法运行时间是从其增速的角度度量的。<br>算法运行时间用大O表示法表示。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/08/python收集（图像识别与文字处理）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="EtanWatson">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EWSUN">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/08/python收集（图像识别与文字处理）/" itemprop="url">python收集（图像识别与文字处理）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-08T21:29:13+08:00">
                2017-10-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python数据收集/" itemprop="url" rel="index">
                    <span itemprop="name">python数据收集</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="图像识别与文字处理"><a href="#图像识别与文字处理" class="headerlink" title="图像识别与文字处理"></a>图像识别与文字处理</h1><p>将图像翻译成文字一般被称为光学文字识别（Optical Character Recognition，OCR）</p>
<h2 id="OCR库概述"><a href="#OCR库概述" class="headerlink" title="OCR库概述"></a>OCR库概述</h2><p>重点介绍两个库：Pillow(<a href="http://pillow.readthedocs.org/installation.html" target="_blank" rel="external">http://pillow.readthedocs.org/installation.html</a> )<br>        Tesseract(<a href="https://pypi.python.org/pypi/pytesseract" target="_blank" rel="external">https://pypi.python.org/pypi/pytesseract</a>)<br>或者使用pip进行安装<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt; pip3 install pillow</div><div class="line">&gt;&gt; pip3 install pytesseract</div></pre></td></tr></table></figure></p>
<h3 id="Pillow"><a href="#Pillow" class="headerlink" title="Pillow"></a>Pillow</h3><p>Pillow也可以轻松的地导入代码，并通过大量的过滤，修饰甚至像素级的变换操作处理图片<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">from  PIL import Image, ImageFilter</div><div class="line"></div><div class="line">kitten = Image.open(<span class="string">"header.png"</span>)</div><div class="line">blurryKitten = kitten.filter(ImageFilter.GaussianBlur)</div><div class="line">blurryKitten.save(<span class="string">'header_blurred.png'</span>)</div><div class="line">blurryKitten.show()</div></pre></td></tr></table></figure></p>
<p>经过处理的图片会变的非常模糊<br>Pillow 还可以完成许多复杂的图像处理工作。更多的信息，请查看 Pillow 文档 (<a href="http://pillow.readthedocs.org/)。" target="_blank" rel="external">http://pillow.readthedocs.org/)。</a></p>
<h3 id="Tesseract"><a href="#Tesseract" class="headerlink" title="Tesseract"></a>Tesseract</h3><p>Tesseract 是目前公认最优秀、最精确的开源 OCR 系统。(由Google赞助)<br>高灵活性：通过训练，可以识别除任何字体<br>Tesseract是一个python的命令行工具（不是通过import语句）<br>安装Tesseract（安装以后，要用tesseract命令在Python的外面运行）<br>Mac OS X系统下：<br>如果没有安装Homebrew，先安装Homebrew</p>
<blockquote>
<p>$ruby -e “$(curl -fsSL <a href="https://raw.githubusercontent.com/Homebrew/" target="_blank" rel="external">https://raw.githubusercontent.com/Homebrew/</a> \ install/master/install)”<br>$brew install tesseract<br>为了能让Tesseract知道训练的数据文件存储在哪里，我们需要配置环境变量<br>$export TESSDATA_PREFIX=/usr/local/share/</p>
</blockquote>
<h3 id="NumPy-训练字符和字体时候，会用到它"><a href="#NumPy-训练字符和字体时候，会用到它" class="headerlink" title="NumPy(训练字符和字体时候，会用到它)"></a>NumPy(训练字符和字体时候，会用到它)</h3><p>在机器学习实战的文章里面有用到</p>
<blockquote>
<p>pip install numpy</p>
</blockquote>
<h2 id="处理格式规范的文字"><a href="#处理格式规范的文字" class="headerlink" title="处理格式规范的文字"></a>处理格式规范的文字</h2><p>通常规范文字的特点<br>• 使用一个标准字体(不包含手写体、草书，或者十分“花哨的”字体) • 虽然被复印或拍照，字体还是很清晰，没有多余的痕迹或污点<br>• 排列整齐，没有歪歪斜斜的字<br>• 没有超出图片范围，也没有残缺不全，或紧紧贴在图片的边缘</p>
<blockquote>
<p>$ tesseract text.png textoutput | cat textoutput.txt<br>Warning in pixReadMemPng: work-around: writing to a temp file</p>
</blockquote>
<h3 id="对于背景渐变以及文字模糊的，可以使用Pillow库预处理，让图片更加清晰"><a href="#对于背景渐变以及文字模糊的，可以使用Pillow库预处理，让图片更加清晰" class="headerlink" title="对于背景渐变以及文字模糊的，可以使用Pillow库预处理，让图片更加清晰"></a>对于背景渐变以及文字模糊的，可以使用Pillow库预处理，让图片更加清晰</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">from PIL import Image</div><div class="line">import subprocess</div><div class="line"></div><div class="line">def cleanFile(filePath, newFilePath):</div><div class="line">    image = Image.open(filePath)</div><div class="line"></div><div class="line">    <span class="comment"># 对图片进行阀值过滤，然后保存</span></div><div class="line">    image = image.point(lambda x: 0 <span class="keyword">if</span> x&lt;143 <span class="keyword">else</span> 255)</div><div class="line">    image.save(newFilePath)</div><div class="line"></div><div class="line">    <span class="comment"># 调用系统的tesseract</span></div><div class="line">    subprocess.call([<span class="string">"tesseract"</span>, newFilePath, <span class="string">"output"</span>])</div><div class="line"></div><div class="line">    <span class="comment"># 打开文件读取结果</span></div><div class="line">    outputFile = open(<span class="string">"output.txt"</span>, <span class="string">'r'</span>)</div><div class="line">    <span class="built_in">print</span>((outputFile.read()))</div><div class="line">    outputFile.close()</div><div class="line">cleanFile(<span class="string">"text_2.jpg"</span>,<span class="string">"text_2_clean.png"</span>)</div></pre></td></tr></table></figure>
<h3 id="从网站图片中抓取文字"><a href="#从网站图片中抓取文字" class="headerlink" title="从网站图片中抓取文字"></a>从网站图片中抓取文字</h3><pre><code class="bash">import time 
from urllib.request import urlretrieve
import subprocess
from selenium import webdriver

<span class="comment">## 读取验证码与训练Tesseract</span>
PHP内容管理系统Drupal有一个著名的验证码模块，https://www.drupal.org/project/captcha,可以生成不同难度
的验证码。
<span class="variable">$tesseract</span> captchaExample.png captcha | cat captcha.txt
&gt;&gt; 4MMCJ

<span class="comment">### 训练Tesseract</span>
矩形定位文件（box file），一个验证码图片生成一个矩形定位文件，一个图片的矩形定位文件如下所示：
    ··4 15 26 33 55 0
      M 38 13 67 45 0
      m 79 15 101 26 0
      C 111 33 136 60 0
      3 147 17 176 45 0
第一列符号是图片中的每个字符，后面的 4 个数字分别是包围这个字符的最小矩形的坐标 (图片左下角是原点 (0,0)，4 个数字分别对应每个字符的左下角 x 坐标、左下角 y 坐标、右上角 x 坐标和右上角 y 坐标)，最后一个数字“0”表示图片样本的编号。
在线工具Tesseract OCR Chopper(http://pp19dd.com/tesseract-ocr-chopper/)
矩形定位文件必须保存在一个.box后缀的文本文件中。和图片文件一样，文本文件也是用验证码的世纪结果命名（例如，4MmC3.box）
https://github.com/REMitchell/tesseract-trainer(OReilly.Web.Scraping.with.Python.2015.6的书的作者写的一个同时包图片和.box文件) 

def main(self):
    languageName = “eng”
    fontName = “captchaFont”
    directory = “”

def runAll(self):
    self.createFontFile()
    self.cleanImages()
    self.renameFiles()
    self.extractUnicode()
    self.runShapeClustering() 
    self.runMfTraining() 
    self.runCnTraining() 
    self.createTessData()

* language 
Tesseract 用三个字母的语言缩写代码表示识别的语言种类。可能大多数情况下，你都会 用“eng”表示英语(English)。
* fontName 
表示你选择的字体名称，可以是任意名称，但必须是一个不包含空格的单词。
* directory
表示包含所有图片和 .box 文件的目录。建议你使用文件夹的绝对路径，但是如果你使 用相对路径，可能需要以 Python 代码运行的目录位置为原点。如果你使用绝对路径， 就可以在电脑的任意位置运行代码了。

* runAll里每个函数的用法
1.createFontFile 创建了一个 font_properties 文件，让 Tesseract 知道我们要创建的新字体:
captchaFont 0 0 0 0 0（这个文件包括字体的名称，后面跟着若干 1 和 0，分别表示应该使用斜体、加粗或其他版 本的字体）
2.cleanImages 首先创建所有样本图片的高对比度版本，然后转换成灰度图，并进行一些清 理，让 Tesseract 更容易读取图片文件。如果你要处理的验证码图片上面有一些很容易过滤 掉的噪点，那么你可以在这里增加一些步骤来处理它们。
3.renameFiles 把所有的图片文件和 .box 文件的文件名改变成 Tesseract 需要的形式 (fileNumber 是文件序号，用来区别每个文件):
• &lt;languageName&gt;.&lt;fontName&gt;.exp&lt;fileNumber&gt;.box • &lt;languageName&gt;.&lt;fontName&gt;.exp&lt;fileNumber&gt;.tiff
4.extractUnicode 函数会检查所有已创建的 .box 文件，确定要训练的字符集范围。抽取出的 Unicode 会告诉你一共找到了多少个不重复的字符，这也是一个查询字符的好方法，如果 你漏了字符可以用这个结果快速排查。
5.之后的三个函数，runShapeClustering、runMfTraining 和 runCtTraining 分别用来创建 文件 shapetable、pfftable 和 normproto。它们会生成每个字符的几何和形状信息，也为 Tesseract 提供计算字符若干可能结果的概率统计信息。
6.最后，Tesseract 会用之前设置的语言名称对数据文件夹编译出的每个文件进行重命名(例 如，shapetable 被重命名为 eng.shapetable)，然后把所有的文件编译到最终的训练文件 eng. traineddata 中。
你需要做的，就是用下面的Linux和Mac命令行把刚刚创建的eng.traineddata文件复制到tessdata文件夹里
<span class="variable">$cp</span> /path/to/data/eng.traineddata <span class="variable">$TESSDATA_PREFIX</span>/tessdata(输入自己的路径)

上面只是对Tesseract库强大的字体训练和识别能力的一个简略的概述。详细阅读Tesseract 的文档
(https://github.com/tesseract-ocr/tesseract/wiki)。
<span class="comment">## 获取验证码提交答案</span>
大多数网站生成的验证码图片都具有以下属性
• 它们是服务器端的程序动态生成的图片。验证码图片的src属性可能和普通图片不太一 样，比如&lt;img src=<span class="string">"WebForm.aspx?id=8AP85CQKE9TJ"</span>&gt;，但是可以和其他图片一样进行 下载和处理。
• 图片的答案存储在服务器端的数据库里。
• 很多验证码都有时间限制，如果你太长时间没解决就会失效。虽然这对网络机器人来说
 不是什么问题，但是如果你想保留验证码的答案一会儿再使用，或者想通过一些方法延
 长验证码的有效时限，可能很难成功。
常用的办法就是，首先把验证码图片下载到硬盘里，清理干净，然后用Tesseract处理图片，最后返回符合网站要求的识别结果
<span class="comment">### 演示如何用网络机器人破解验证码</span>
``` bash 
from urllib.request import urlretrieve
from urllib.request import urlopen
from bs4 import BeautifulSoup
import subprocess
import requests
from PIL import Image
from PIL import ImageOps

def cleanImage(imagePath):
    image = Image.open(imagePath)
    image = Image.point(lambda x: 0 <span class="keyword">if</span> x &lt; 143 <span class="keyword">else</span> 255)
    borderImage = ImageOps.expand(image, border=20, fill=<span class="string">'white'</span>)
    borderImage.save(imagePath)

html = urlopen(<span class="string">"http://www.pythonscraping.com/humans-only"</span>)
bsObj = BeautifulSoup(html)
<span class="comment"># 收集需要处理的表单数据（包括验证码和输入字段）</span>
imageLocation = bsObj.find(<span class="string">"img"</span>,{<span class="string">"title"</span>: <span class="string">"Image CAPTCHA"</span>})[<span class="string">"src"</span>]
fromBuildId = bsObj.find(<span class="string">"input"</span>,{<span class="string">"name"</span>: <span class="string">"from_build_id"</span>})[<span class="string">"value"</span>]
captchaSid = bsObj.find(<span class="string">"input"</span>, {<span class="string">"name"</span>: <span class="string">"captcha_sid"</span>})[<span class="string">"value"</span>]
captchaToken = bsObj.find(<span class="string">"input"</span>, {<span class="string">"name"</span>: <span class="string">"captcha_token"</span>})[<span class="string">"value"</span>]

captchaUrl = <span class="string">"http://pythonscraping.com"</span>+imageLocation
urlretrieve(captchaUrl,<span class="string">'captcha.jpg'</span>)
cleanImage(<span class="string">"captcha,jpg"</span>)
p = subprocess.Popen([<span class="string">"tesseract"</span>, <span class="string">"captcha.jpg"</span>, <span class="string">"captcha"</span>],stdout=
                     subprocess.PIPE,stderr=subprocess.PIPE)
p.wait()
f = open(<span class="string">"captcha.txt"</span>, <span class="string">'r'</span>)

<span class="comment"># 清理识别结果中的空格和换行符</span>
captchResponse = f.read().replace(<span class="string">" "</span>,<span class="string">""</span>).replace(<span class="string">"\n"</span>,<span class="string">""</span>)
<span class="built_in">print</span>(<span class="string">"Capcha solution attempt: "</span> + captchResponse)

<span class="keyword">if</span> len(captchResponse) == 5:
    params = {<span class="string">"captcha_token"</span>:captchaToken, <span class="string">"captcha_sid"</span>:fromBuildId,
                <span class="string">"captcha_response"</span>:captchResponse, <span class="string">"name"</span>:<span class="string">"Ryan Mitchell"</span>,
                <span class="string">"subject"</span>: <span class="string">"I come to seek the Grail"</span>,
                <span class="string">"comment_body[und][0][value]"</span>:<span class="string">"...and I am definitely not a bot"</span>
              }
    r = requests.post(<span class="string">"http://www.pythonscraping.com/comment/reply/10"</span> ,data=params)
    responseObj = BeautifulSoup(<span class="string">'r.text'</span>)
    <span class="keyword">if</span> responseObj.find(<span class="string">"div"</span>,{<span class="string">"class"</span>:<span class="string">"messages"</span>}) is not None:
        <span class="built_in">print</span>(responseObj.find(<span class="string">"div"</span>, {<span class="string">"class"</span>:<span class="string">"messages"</span>}).get_text())
    <span class="keyword">else</span>:
        <span class="built_in">print</span>(<span class="string">"There was a problem reading the CAPTCHA correctly"</span>)
</code></pre>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/07/python数据采集（采集JavaScript）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="EtanWatson">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EWSUN">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/07/python数据采集（采集JavaScript）/" itemprop="url">python数据采集（采集JavaScript）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-07T14:33:28+08:00">
                2017-10-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python数据收集/" itemprop="url" rel="index">
                    <span itemprop="name">python数据收集</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="采集JavaScript"><a href="#采集JavaScript" class="headerlink" title="采集JavaScript"></a>采集JavaScript</h1><h2 id="常用的JavaScript库"><a href="#常用的JavaScript库" class="headerlink" title="常用的JavaScript库"></a>常用的JavaScript库</h2><h3 id="jQuery"><a href="#jQuery" class="headerlink" title="jQuery"></a>jQuery</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;script src=<span class="string">"http://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"</span>&gt;&lt;/ script&gt;</div></pre></td></tr></table></figure>
<h3 id="Google-Analytics"><a href="#Google-Analytics" class="headerlink" title="Google Analytics"></a>Google Analytics</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">&lt;!-- Google Analytics --&gt;&lt;script <span class="built_in">type</span>=<span class="string">"text/javascript"</span>&gt;</div><div class="line">var _gaq = _gaq || []; </div><div class="line">_gaq.push([<span class="string">'_setAccount'</span>, <span class="string">'UA-4591498-1'</span>]); </div><div class="line">_gaq.push([<span class="string">'_setDomainName'</span>, <span class="string">'oreilly.com'</span>]); </div><div class="line">_gaq.push([<span class="string">'_addIgnoredRef'</span>, <span class="string">'oreilly.com'</span>]); </div><div class="line">_gaq.push([<span class="string">'_setSiteSpeedSampleRate'</span>, 50]); </div><div class="line">_gaq.push([<span class="string">'_trackPageview'</span>]);(<span class="function"><span class="title">function</span></span>() &#123; var ga = document.createElement(<span class="string">'script'</span>); </div><div class="line">ga.type = <span class="string">'text/javascript'</span>; </div><div class="line">ga.async = <span class="literal">true</span>; </div><div class="line">ga.src = (<span class="string">'https:'</span> == document.location.protocol ? <span class="string">'https://ssl'</span> : <span class="string">'http://www'</span>) + <span class="string">'.google-analytics.com/ga.js'</span>; </div><div class="line">var s = document.getElementsByTagName(<span class="string">'script'</span>)[0]; s.parentNode.insertBefore(ga, s); &#125;();&lt;/script&gt;</div><div class="line">``` </div><div class="line"><span class="comment">### Google地图</span></div><div class="line">``` bash </div><div class="line">var marker = new google.maps.Marker(&#123;	position: new google.maps.LatLng(-25.363882,131.044922), </div><div class="line">	map: map,	title: <span class="string">'Some marker text'</span>&#125;);</div><div class="line"><span class="comment">### Ajax（异步JavaScript和XML）和动态HTML（有没有用JavaScript控制HTML和CSS元素）</span></div><div class="line">解决方案：</div><div class="line">1.直接从JavaScript代码里采集内容。</div><div class="line">2.用Python的第三方运行JavaScript，直接采集你在浏览器里看到的页面</div><div class="line"><span class="comment">### 在Python中用Selenium执行JavaScript</span></div><div class="line">Selenium是一个强大的网络数据采集工具，它还被广泛用于获取精确的网站快照，因为它们可以直接运行在浏览器上</div><div class="line">phantomJS是一个无头（headless）浏览器</div><div class="line">Selenium库是一个在WebDriver上调用的API。WebDriver有点儿想可以加载网站的浏览器，但是它也可以像BeautifulSoup对象一样用来查找页面元素，与页面上的元素进行交互（发送文本，点击等），以及执行其他动作来运行</div><div class="line">网络爬虫</div><div class="line">下面代码可以获取前面测试页面上Ajax”墙”后面的内容</div><div class="line">``` bash </div><div class="line">from selenium import webdriver</div><div class="line">import time</div><div class="line">diver = webdriver.PhantomJS(executable_path=‘’) <span class="comment">#你的PhantomJS可执行文件的路径</span></div><div class="line">driver.get(<span class="string">"http://pythonscraping.com/pages/javascript/ajaxDemo.html"</span>)</div><div class="line">time.sleep(3)</div><div class="line"><span class="built_in">print</span>(driver.find_element_by_id(‘content’).text)</div><div class="line">driver.close()</div></pre></td></tr></table></figure>
<p>#这种方法虽然奏效，但是效率还不高，由于页面加载时间的不确定性，所有有很大的弊端</p>
<h4 id="Selenium的选择器"><a href="#Selenium的选择器" class="headerlink" title="Selenium的选择器"></a>Selenium的选择器</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">driver.find_element_by_id(<span class="string">'content'</span>).text</div><div class="line">driver.find_element_by_css_selector(<span class="string">"#content"</span>)driver.find_element_by_tag_name(<span class="string">"div"</span>)</div><div class="line">driver.find_elements_by_css_selector(<span class="string">"#content"</span>)driver.find_elements_by_css_selector(<span class="string">"div"</span>)</div><div class="line"><span class="comment">#另外，如果你还想用BeautifulSoup来解析网页内容，可以用WebDriver的page_source</span></div><div class="line">pageSource = driver.page_sourcebsObj = BeautifulSoup(pageSource) </div><div class="line"><span class="built_in">print</span>(bsObj.find(id=<span class="string">"content"</span>).get_text())</div><div class="line">``` </div><div class="line"><span class="comment">#### 使用Selenium不断检查，是否完全加载</span></div><div class="line">``` bash </div><div class="line">from selenium.webdriver.common.by import By</div><div class="line">from selenium.webdriver.support.ui import WebDriverWait</div><div class="line">from selenium.webdriver.support import expected_conditions as EC</div><div class="line">from selenium import webdriver</div><div class="line">import time</div><div class="line"></div><div class="line">driver = webdriver.PhantomJS(executable_path=<span class="string">''</span>)</div><div class="line">driver.get(<span class="string">"http://pythonscraping.com/pages/javascript/ajaxDemo.html"</span>)</div><div class="line">try:</div><div class="line">    element = WebDriverWait(driver, 10).until(</div><div class="line">        EC.presence_of_all_elements_located((By.ID, <span class="string">"loadedButton"</span>)))</div><div class="line">finally:</div><div class="line">    <span class="built_in">print</span>(driver.find_element_by_id(<span class="string">"content"</span>).text)</div><div class="line">    driver.close()</div></pre></td></tr></table></figure>
<p>需要注意的就是WebDriverWait和expected_conditions,这两个模块组合起来，构成了Selenium的隐式等待</p>
<h5 id="Selenium隐式等待"><a href="#Selenium隐式等待" class="headerlink" title="Selenium隐式等待"></a>Selenium隐式等待</h5><p>1.没有明确的等待时间，但是有最大等待时间</p>
<p>#DOM触发的状态是用expected_conditions定义的<br>• 弹出一个提示框<br>• 一个元素被选中(比如文本框)<br>• 页面的标题改变了，或者某个文字显示在页面上或者某个元素里 • 一个元素在DOM中变成可见的，或者一个元素从DOM中消失了</p>
<h5 id="定位器"><a href="#定位器" class="headerlink" title="定位器"></a>定位器</h5><p>大多数的期望条件在使用前都需要你先指定等待的目标元素，定位器是一种抽象的查询语言，用 By 对象表示，可以用于不同的场合，包括创建选择器。<br>一个定位器被用来查找id是loadedButton -&gt; EX：<br>EC.presence_of_element_located((By.ID, “loadedButton”))<br>定位器还可以用来创建选择器，配合WebDriver的find_element函数使用：<br>print(driver.find_element(By.ID, “content”).text)<br>下面这行代码的功能和示例代码中一样：<br>print(driver.find_element_by_id(“content”).text)</p>
<p>下面是定位器通过By对象进行选择的策略<br>• ID<br>• CLASS_NAME(HTML的class属性)<br>• CSS_SELECTOR:通过 CSS 的 class、id、tag 属性名来查找元素，<br>           用 #idName、.className、tagName 表示。<br>• LINK_TEXT：通过链接文字查找 HTML 的 <a> 标签。例如，如果一个链接的文字是“Next”，就可以 用(By.LINK_TEXT, “Next”)来选择。<br>• PARTIAL_LINK_TEXT：与 LINK_TEXT 类似，只是通过部分链接文字来查找。<br>• NAME：通过 HTML 标签的 name 属性查找。这在处理 HTML 表单时非常方便。<br>• TAG_NAME：通过 HTML 标签的名称查找。<br>• XPATH：用 XPath 表达式(语法在下面介绍)选择匹配的元素。</a></p>
<h6 id="XPath语法"><a href="#XPath语法" class="headerlink" title="XPath语法"></a>XPath语法</h6><p>在XPath语法中有四个重要概念。<br>一、根节点和非根节点</p>
<ol>
<li>/div选择div节点，只有当它是文档的根节点时</li>
<li>//div选择文档中所有的div节点（包括非根节点）<br>二、通过属性选择节点</li>
<li>//@href选择带href属性的所有节点</li>
<li>//a[@href=‘<a href="http://google.com’]选择页面中所有指向Google网站的链接" target="_blank" rel="external">http://google.com’]选择页面中所有指向Google网站的链接</a><br>三、通过位置选择节点</li>
<li>//a[3]选着文档中的第三个链接</li>
<li>//table[last()]选择文档中的最后一个表</li>
<li>//a[positon() &lt; 3]选择文档中的前三个链接<br>四、星号（*）匹配任意字符串或节点，可以在不同条件下使用</li>
<li>//table/tr/*选择所有表格行tr标签的所有子节点（这很适合选择th和td标签）</li>
<li>//div[@0]选择带有任意属性的所有div标签<br>更多，请参考微软的XPath语法页面：<a href="https://msdn.microsoft.com/en-us/enus/library/ms256471" target="_blank" rel="external">https://msdn.microsoft.com/en-us/enus/library/ms256471</a></li>
</ol>
<h2 id="处理重定向"><a href="#处理重定向" class="headerlink" title="处理重定向"></a>处理重定向</h2><h3 id="客户端重定向"><a href="#客户端重定向" class="headerlink" title="客户端重定向"></a>客户端重定向</h3><p>是在服务器将页面内容发送到浏览器之前，由浏览器执行 JavaScript 完成的 页面跳转，而不是服务器完成的跳转。<br>在网络采集是的差异：（客户端重定向和服务端重定向）<br>根据具体情况，<br>服务器端重定向一般都可以轻松地通过 Python 的 urllib 库解决，不需要使用 Selenium (更多的介绍请参考第 3 章)。客户端重定向却不能这样处理，除非你有工具可以执行<br>JavaScript。<br>Selenium的问题在于怎么识别一个页面已经完成重定向了</p>
<h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>首先从页面开始加载时就”监视”DOM中的一个元素，然后重复调用这个元素直到Selenium抛出一个StaleElementRefereceException异常，也就是说，元素不在页面的DOM里了，说明这时网站已经跳转：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">from selenium import webdriver</div><div class="line">import time</div><div class="line">from selenium.webdriver.remote.webelement import WebElement</div><div class="line">from selenium.common.exceptions import StaleElementReferenceException</div><div class="line"></div><div class="line">def waitForLoad(driver):</div><div class="line">    elem = driver.find_element_by_tag_name(<span class="string">"html"</span>)</div><div class="line">    count = 0</div><div class="line">    <span class="keyword">while</span> True:</div><div class="line">        count += 1</div><div class="line">        <span class="keyword">if</span> count &gt; 20:</div><div class="line">            <span class="built_in">print</span>(<span class="string">"Timing out after 10 secods and returning"</span>)</div><div class="line">            <span class="built_in">return</span></div><div class="line">        time.sleep(.5)</div><div class="line">        try:</div><div class="line">            elem == driver.find_element_by_tag_name(<span class="string">"html"</span>)</div><div class="line">        except StaleElementReferenceException:</div><div class="line">            <span class="built_in">return</span></div><div class="line">driver = webdriver.PhantomJS(executable_path=“/****/**/MachineLearning/phantomjs-2.1.1-macosx/bin/phantomjs<span class="string">")</span></div><div class="line"><span class="string">driver.get("</span>http://pythonscraping.com/pages/javascript/redirectDemo1.html<span class="string">")</span></div><div class="line"><span class="string">waitForLoad(driver)</span></div><div class="line"><span class="string">print(driver.page_source)</span></div></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/07/python数据收集（穿越网页表单与登录窗口进行采集）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="EtanWatson">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EWSUN">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/07/python数据收集（穿越网页表单与登录窗口进行采集）/" itemprop="url">python数据收集（穿越网页表单与登录窗口进行采集）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-07T10:47:05+08:00">
                2017-10-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python数据收集/" itemprop="url" rel="index">
                    <span itemprop="name">python数据收集</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="穿越网页表单与登录窗口进行采集"><a href="#穿越网页表单与登录窗口进行采集" class="headerlink" title="穿越网页表单与登录窗口进行采集"></a>穿越网页表单与登录窗口进行采集</h1><p>如何获取登录窗口背后的信息呢？？？这一节我们重点介绍POST方法，即把消息推送给网络服务器进行存储和分析，像网站搞得URL链接可以帮助用户发送GET请求一样，HTML表单可以帮助用户发出POST请求</p>
<h2 id="Python-Requests-库（http-www-python-requests-org-）"><a href="#Python-Requests-库（http-www-python-requests-org-）" class="headerlink" title="Python Requests 库（http://www.python-requests.org/）"></a>Python Requests 库（<a href="http://www.python-requests.org/）" target="_blank" rel="external">http://www.python-requests.org/）</a></h2><p>是一个擅长处理那些复杂的HTTP请求。cookie，header（响应头和请求头）等内容的Python第三方库。<br>安装：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt;&gt; pip(pip3) install Requests</div></pre></td></tr></table></figure></p>
<h2 id="提交一个基本表单"><a href="#提交一个基本表单" class="headerlink" title="提交一个基本表单"></a>提交一个基本表单</h2><p>注：如果你想模拟表单提交数据的行为，你就需要保证你的变量名称与字段名称是一一对应的</p>
<h3 id="一个简单的例子"><a href="#一个简单的例子" class="headerlink" title="一个简单的例子"></a>一个简单的例子</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">import requests</div><div class="line"></div><div class="line">params = &#123;<span class="string">'firstname'</span>: <span class="string">'Ryan'</span>, <span class="string">'listname'</span>: <span class="string">'Mitchell'</span>&#125;</div><div class="line">r = requests.post(<span class="string">"http://pythonscraping.com/files/processing.php"</span>, data=params)</div><div class="line"><span class="built_in">print</span>(r.text)</div><div class="line"><span class="comment">#在大多数情况下，你只需关注两件事：</span></div><div class="line"><span class="comment">#• 你想提交数据的字段名称（name字段）(在这个例子中是email_addr)</span><span class="comment">#• 表单的action属性，也就是表单提交后网站会显示的页面(在这个例子中是http://post.oreilly.com</span></div><div class="line"><span class="comment">#/client/o/oreilly/forms/quicksignup.cgi)</span></div><div class="line"><span class="comment">#运行代码示例</span></div><div class="line">import requestsparams = &#123;<span class="string">'email_addr'</span>: <span class="string">'ryan.e.mitchell@gmail.com'</span>&#125;r = requests.post(<span class="string">"http://post.oreilly.com/client/o/oreilly/forms/                        quicksignup.cgi"</span>, data=params)<span class="built_in">print</span>(r.text)</div></pre></td></tr></table></figure>
<h2 id="单选按钮、复选框和其他输入"><a href="#单选按钮、复选框和其他输入" class="headerlink" title="单选按钮、复选框和其他输入"></a>单选按钮、复选框和其他输入</h2><p>无论html提供了多么复杂的控件，仍然只有亮剑事是需要关注的：字段名称（name）和值（比较复杂，有可能是通过JavaScript生成的，<br>而取色器有类似于#F03030这样的值）</p>
<h3 id="跟踪GET请求获取值"><a href="#跟踪GET请求获取值" class="headerlink" title="跟踪GET请求获取值"></a>跟踪GET请求获取值</h3><p>get请求的值一般会在URL中体现，类似于：<a href="http://domainname.com?thing1=foo&amp;thing2=bar" target="_blank" rel="external">http://domainname.com?thing1=foo&amp;thing2=bar</a></p>
<p>你就会明白这个请求就是下面这种表单：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;form method=<span class="string">"GET"</span> action=<span class="string">"someProcessor.php"</span>&gt;&lt;input <span class="built_in">type</span>=<span class="string">"someCrazyInputType"</span> name=<span class="string">"thing1"</span> value=<span class="string">"foo"</span> /&gt; &lt;input <span class="built_in">type</span>=<span class="string">"anotherCrazyInputType"</span> name=<span class="string">"thing2"</span> value=<span class="string">"bar"</span> /&gt; &lt;input <span class="built_in">type</span>=<span class="string">"submit"</span> value=<span class="string">"Submit"</span> /&gt;&lt;/form&gt;</div></pre></td></tr></table></figure></p>
<p>对应的python参数就是：<br>{‘thing1’:’foo’, ‘thing2’:’bar’}</p>
<h2 id="提交文件和图像"><a href="#提交文件和图像" class="headerlink" title="提交文件和图像"></a>提交文件和图像</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">files = &#123;<span class="string">'uploadFile'</span>: open(<span class="string">'./files/header.png'</span>, <span class="string">'rb'</span>)&#125;</div><div class="line">r = requests.post(<span class="string">"http://pythonscraping.com/pages/processing2.php"</span>,files=files)</div><div class="line"></div><div class="line"><span class="built_in">print</span>(r.text)</div></pre></td></tr></table></figure>
<h2 id="处理登录和cookie"><a href="#处理登录和cookie" class="headerlink" title="处理登录和cookie"></a>处理登录和cookie</h2><p>问题：你可以一整天只提交一次登录表单，但是如果你没有一直关注表单后来回传给你的那个cookie，那么一段时间以后再次访问新页面<br>时，你的登录状态就会丢失，需要重新登录<br>Requests库跟踪cookie同样简单：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">import requests</div><div class="line">params = &#123;‘username’:’Ryan’,’password’:’password’&#125;</div><div class="line">r = requests.post(<span class="string">"http://pythonscraping.com/pages/cookies/welcome.php"</span>, params) </div><div class="line"><span class="built_in">print</span>(<span class="string">"Cookie is set to:"</span>)<span class="built_in">print</span>(r.cookies.get_dict())<span class="built_in">print</span>(<span class="string">"-----------"</span>)<span class="built_in">print</span>(<span class="string">"Going to profile page..."</span>)r = requests.get(<span class="string">"http://pythonscraping.com/pages/cookies/profile.php"</span>,                      cookies=r.cookies)<span class="built_in">print</span>(r.text)</div></pre></td></tr></table></figure></p>
<h3 id="使用session"><a href="#使用session" class="headerlink" title="使用session"></a>使用session</h3><p>如果你面对的网站比较复杂，它经常暗自调整cookie，或者如果你从一开始就完全不想要用cookie，该如何处理呢</p>
<h3 id="HTTP基本接入认证"><a href="#HTTP基本接入认证" class="headerlink" title="HTTP基本接入认证"></a>HTTP基本接入认证</h3><p>RRequests库有一个auth模块专门用来处理HTTP认证：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">import requests</div><div class="line">from requests.auth import AuthBase</div><div class="line">from request.auth import HTTPBasicAuth</div><div class="line"></div><div class="line">auth = HTTPBasicAuth(<span class="string">'ryan'</span>, <span class="string">'password'</span>)     r = requests.post(url=<span class="string">"http://pythonscraping.com/pages/auth/login.php"</span>, auth=auth)<span class="built_in">print</span>(r.text)</div></pre></td></tr></table></figure></p>
<h2 id="其他表单问题（CAPTCHA-验证码）"><a href="#其他表单问题（CAPTCHA-验证码）" class="headerlink" title="其他表单问题（CAPTCHA:验证码）"></a>其他表单问题（CAPTCHA:验证码）</h2>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/04/python数据收集（自然语言处理）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="EtanWatson">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EWSUN">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/04/python数据收集（自然语言处理）/" itemprop="url">python数据收集（自然语言处理）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-04T11:08:41+08:00">
                2017-10-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python数据收集/" itemprop="url" rel="index">
                    <span itemprop="name">python数据收集</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="自然语言的处理"><a href="#自然语言的处理" class="headerlink" title="自然语言的处理"></a>自然语言的处理</h1><h2 id="概括数据"><a href="#概括数据" class="headerlink" title="概括数据"></a>概括数据</h2><p>前面已经介绍过了n-gram模型，即n个单词长度的词组<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">from urllib.request import urlopen</div><div class="line">from bs4 import BeautifulSoup</div><div class="line">import re</div><div class="line">import string</div><div class="line">import operator</div><div class="line"></div><div class="line">def cleanInput(input):</div><div class="line">    input = re.sub(<span class="string">'\n+'</span>,<span class="string">" "</span>,input).lower()</div><div class="line">    input = re.sub(<span class="string">'\[[0-9]*\]'</span>,<span class="string">""</span>,input)</div><div class="line">    input = re.sub(<span class="string">' +'</span>, <span class="string">" "</span>, input)</div><div class="line">    input = bytes(input, <span class="string">"UTF-8"</span>)</div><div class="line">    input = input.decode(<span class="string">"ascii"</span>, <span class="string">"ignore"</span>)</div><div class="line">    cleanInput = []</div><div class="line">    input = input.split(<span class="string">' '</span>)</div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> input:</div><div class="line">        item = item.strip(string.punctuation)</div><div class="line">        <span class="keyword">if</span> len(item) &gt; 1 or (item.lower() == <span class="string">'a'</span> or item.lower() == <span class="string">'i'</span>):</div><div class="line">            cleanInput.append(item)</div><div class="line">    <span class="built_in">return</span> cleanInput</div><div class="line"></div><div class="line">def ngrams(input, n):</div><div class="line">    input = cleanInput(input)</div><div class="line">    output = &#123;&#125;</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(input)-n+1):</div><div class="line">        ngramTemp =<span class="string">" "</span>.join(input[i:i+n])</div><div class="line">        <span class="keyword">if</span> ngramTemp not <span class="keyword">in</span> output:</div><div class="line">            output[ngramTemp] = 0</div><div class="line">        output[ngramTemp] += 1</div><div class="line">    <span class="built_in">return</span> output</div><div class="line"></div><div class="line">content = str(urlopen(<span class="string">"http://pythonscraping.com/files/inaugurationSpeech.txt"</span>).<span class="built_in">read</span>(),<span class="string">'utf-8'</span>)</div><div class="line">ngrams = ngrams(content, 2)</div><div class="line">sortedNGrams = sorted(ngrams.items(), key=operator.itemgetter(1), reverse=True)</div><div class="line"><span class="built_in">print</span>(sortedNGrams)</div><div class="line"><span class="comment">#结果</span></div><div class="line">&gt;&gt;&gt; (<span class="string">'of the'</span>, 213), (<span class="string">'in the'</span>, 65), (<span class="string">'to the'</span>, 61), (<span class="string">'by the'</span>, 41), (<span class="string">'the constitution'</span>, 34),</div></pre></td></tr></table></figure></p>
<p>我们会发现，其实像of the，in the ，对我们来讲一点儿都不重要，而 the constitution相对来说就比较重要</p>
<h3 id="去掉看上去无用的字符"><a href="#去掉看上去无用的字符" class="headerlink" title="去掉看上去无用的字符"></a>去掉看上去无用的字符</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div></pre></td><td class="code"><pre><div class="line">from urllib.request import urlopen</div><div class="line">from bs4 import BeautifulSoup</div><div class="line">import re</div><div class="line">import string</div><div class="line">import operator</div><div class="line"></div><div class="line"><span class="comment">#最常用的5000个单词列表可以免费获取，我们现在提取出前100个</span></div><div class="line"><span class="comment">#返回boolean类型，如果包含，就返回true</span></div><div class="line">def isCommon(ngram):</div><div class="line">    commonWords = [<span class="string">"the"</span>, <span class="string">"be"</span>, <span class="string">"and"</span>, <span class="string">"of"</span>, <span class="string">"a"</span>, <span class="string">"in"</span>, <span class="string">"to"</span>, <span class="string">"have"</span>, <span class="string">"it"</span>,</div><div class="line">             <span class="string">"i"</span>, <span class="string">"that"</span>, <span class="string">"for"</span>, <span class="string">"you"</span>, <span class="string">"he"</span>, <span class="string">"with"</span>, <span class="string">"on"</span>, <span class="string">"do"</span>, <span class="string">"say"</span>, <span class="string">"this"</span>,</div><div class="line">             <span class="string">"they"</span>, <span class="string">"is"</span>, <span class="string">"an"</span>, <span class="string">"at"</span>, <span class="string">"but"</span>,<span class="string">"we"</span>, <span class="string">"his"</span>, <span class="string">"from"</span>, <span class="string">"that"</span>, <span class="string">"not"</span>,</div><div class="line">             <span class="string">"by"</span>, <span class="string">"she"</span>, <span class="string">"or"</span>, <span class="string">"as"</span>, <span class="string">"what"</span>, <span class="string">"go"</span>, <span class="string">"their"</span>,<span class="string">"can"</span>, <span class="string">"who"</span>, <span class="string">"get"</span>,</div><div class="line">             <span class="string">"if"</span>, <span class="string">"would"</span>, <span class="string">"her"</span>, <span class="string">"all"</span>, <span class="string">"my"</span>, <span class="string">"make"</span>, <span class="string">"about"</span>, <span class="string">"know"</span>, <span class="string">"will"</span>,</div><div class="line">             <span class="string">"as"</span>, <span class="string">"up"</span>, <span class="string">"one"</span>, <span class="string">"time"</span>, <span class="string">"has"</span>, <span class="string">"been"</span>, <span class="string">"there"</span>, <span class="string">"year"</span>, <span class="string">"so"</span>,</div><div class="line">             <span class="string">"think"</span>, <span class="string">"when"</span>, <span class="string">"which"</span>, <span class="string">"them"</span>, <span class="string">"some"</span>, <span class="string">"me"</span>, <span class="string">"people"</span>, <span class="string">"take"</span>,</div><div class="line">             <span class="string">"out"</span>, <span class="string">"into"</span>, <span class="string">"just"</span>, <span class="string">"see"</span>, <span class="string">"him"</span>, <span class="string">"your"</span>, <span class="string">"come"</span>, <span class="string">"could"</span>, <span class="string">"now"</span>,</div><div class="line">             <span class="string">"than"</span>, <span class="string">"like"</span>, <span class="string">"other"</span>, <span class="string">"how"</span>, <span class="string">"then"</span>, <span class="string">"its"</span>, <span class="string">"our"</span>, <span class="string">"two"</span>, <span class="string">"more"</span>,</div><div class="line">             <span class="string">"these"</span>, <span class="string">"want"</span>, <span class="string">"way"</span>, <span class="string">"look"</span>, <span class="string">"first"</span>, <span class="string">"also"</span>, <span class="string">"new"</span>, <span class="string">"because"</span>,</div><div class="line">             <span class="string">"day"</span>, <span class="string">"more"</span>, <span class="string">"use"</span>, <span class="string">"no"</span>, <span class="string">"man"</span>, <span class="string">"find"</span>, <span class="string">"here"</span>, <span class="string">"thing"</span>, <span class="string">"give"</span>,</div><div class="line">             <span class="string">"many"</span>, <span class="string">"well"</span>]</div><div class="line"></div><div class="line">    <span class="keyword">if</span> ngram <span class="keyword">in</span> commonWords:</div><div class="line">        <span class="built_in">return</span> True</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="built_in">return</span> False</div><div class="line"></div><div class="line">def cleanInput(input):</div><div class="line">    input = re.sub(<span class="string">'\n+'</span>,<span class="string">" "</span>,input).lower() <span class="comment"># 匹配换行,用空格替换换行符</span></div><div class="line">    input = re.sub(<span class="string">'\[[0-9]*\]'</span>,<span class="string">""</span>,input) <span class="comment"># 剔除类似[1]这样的引用标记</span></div><div class="line">    input = re.sub(<span class="string">' +'</span>, <span class="string">" "</span>, input) <span class="comment">#把连续多个空格替换成一个空格</span></div><div class="line">    input = bytes(input, <span class="string">"UTF-8"</span>)</div><div class="line">    input = input.decode(<span class="string">"ascii"</span>, <span class="string">"ignore"</span>)</div><div class="line">    cleanInput = []</div><div class="line">    input = input.split(<span class="string">' '</span>)</div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> input:</div><div class="line">        item = item.strip(string.punctuation)</div><div class="line">        <span class="keyword">if</span> len(item) &gt; 1 or (item.lower() == <span class="string">'a'</span> or item.lower() == <span class="string">'i'</span>):</div><div class="line">            cleanInput.append(item)</div><div class="line">    <span class="built_in">return</span> cleanInput</div><div class="line"></div><div class="line">def ngrams(input, n):</div><div class="line">    input = cleanInput(input)</div><div class="line">    output = &#123;&#125;</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(input)-n+1):</div><div class="line">        ngramTemp =<span class="string">" "</span>.join(input[i:i+n]) <span class="comment">#这句话将n-grams拆分成n个元素组成的列表</span></div><div class="line">        <span class="keyword">if</span> isCommon(ngramTemp.split()[0]) or isCommon(ngramTemp.split()[1]):</div><div class="line">            pass</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">if</span> ngramTemp not <span class="keyword">in</span> output:</div><div class="line">                output[ngramTemp] = 0</div><div class="line">            output[ngramTemp] += 1</div><div class="line">    <span class="built_in">return</span> output</div><div class="line"></div><div class="line">content = str(urlopen(<span class="string">"http://pythonscraping.com/files/inaugurationSpeech.txt"</span>).<span class="built_in">read</span>(),<span class="string">'utf-8'</span>)</div><div class="line">ngrams = ngrams(content, 2)</div><div class="line">sortedNGrams = sorted(ngrams.items(), key=operator.itemgetter(1), reverse=True)</div><div class="line"><span class="built_in">print</span>(sortedNGrams)</div></pre></td></tr></table></figure>
<p>#结果</p>
<blockquote>
<blockquote>
<blockquote>
<p>[(‘united states’, 10), (‘general government’, 4), (‘executive department’, 4), (‘mr jefferson’, 3), (‘same causes’, 3),……]<br>我的疑惑：在进行”看似无用”的单词过滤的时候，是不是会将有用的单词过滤掉类似the constitution</p>
<h3 id="通过中心主题词，归纳文章核心"><a href="#通过中心主题词，归纳文章核心" class="headerlink" title="通过中心主题词，归纳文章核心"></a>通过中心主题词，归纳文章核心</h3><p>一种方法是搜索包含每个核心 n-gram 序列的第一句话，这个方法的理论是英语中段落的首句 往往是对后面内容的概述<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div></pre></td><td class="code"><pre><div class="line">from urllib.request import urlopen</div><div class="line">from bs4 import BeautifulSoup</div><div class="line">import re</div><div class="line">import string</div><div class="line">import operator</div><div class="line"></div><div class="line"><span class="comment">#最常用的5000个单词列表可以免费获取，我们现在提取出前100个</span></div><div class="line"><span class="comment">#返回boolean类型，如果包含，就返回true</span></div><div class="line">def isCommon(ngram):</div><div class="line">    commonWords = [<span class="string">"the"</span>, <span class="string">"be"</span>, <span class="string">"and"</span>, <span class="string">"of"</span>, <span class="string">"a"</span>, <span class="string">"in"</span>, <span class="string">"to"</span>, <span class="string">"have"</span>, <span class="string">"it"</span>,</div><div class="line">             <span class="string">"i"</span>, <span class="string">"that"</span>, <span class="string">"for"</span>, <span class="string">"you"</span>, <span class="string">"he"</span>, <span class="string">"with"</span>, <span class="string">"on"</span>, <span class="string">"do"</span>, <span class="string">"say"</span>, <span class="string">"this"</span>,</div><div class="line">             <span class="string">"they"</span>, <span class="string">"is"</span>, <span class="string">"an"</span>, <span class="string">"at"</span>, <span class="string">"but"</span>,<span class="string">"we"</span>, <span class="string">"his"</span>, <span class="string">"from"</span>, <span class="string">"that"</span>, <span class="string">"not"</span>,</div><div class="line">             <span class="string">"by"</span>, <span class="string">"she"</span>, <span class="string">"or"</span>, <span class="string">"as"</span>, <span class="string">"what"</span>, <span class="string">"go"</span>, <span class="string">"their"</span>,<span class="string">"can"</span>, <span class="string">"who"</span>, <span class="string">"get"</span>,</div><div class="line">             <span class="string">"if"</span>, <span class="string">"would"</span>, <span class="string">"her"</span>, <span class="string">"all"</span>, <span class="string">"my"</span>, <span class="string">"make"</span>, <span class="string">"about"</span>, <span class="string">"know"</span>, <span class="string">"will"</span>,</div><div class="line">             <span class="string">"as"</span>, <span class="string">"up"</span>, <span class="string">"one"</span>, <span class="string">"time"</span>, <span class="string">"has"</span>, <span class="string">"been"</span>, <span class="string">"there"</span>, <span class="string">"year"</span>, <span class="string">"so"</span>,</div><div class="line">             <span class="string">"think"</span>, <span class="string">"when"</span>, <span class="string">"which"</span>, <span class="string">"them"</span>, <span class="string">"some"</span>, <span class="string">"me"</span>, <span class="string">"people"</span>, <span class="string">"take"</span>,</div><div class="line">             <span class="string">"out"</span>, <span class="string">"into"</span>, <span class="string">"just"</span>, <span class="string">"see"</span>, <span class="string">"him"</span>, <span class="string">"your"</span>, <span class="string">"come"</span>, <span class="string">"could"</span>, <span class="string">"now"</span>,</div><div class="line">             <span class="string">"than"</span>, <span class="string">"like"</span>, <span class="string">"other"</span>, <span class="string">"how"</span>, <span class="string">"then"</span>, <span class="string">"its"</span>, <span class="string">"our"</span>, <span class="string">"two"</span>, <span class="string">"more"</span>,</div><div class="line">             <span class="string">"these"</span>, <span class="string">"want"</span>, <span class="string">"way"</span>, <span class="string">"look"</span>, <span class="string">"first"</span>, <span class="string">"also"</span>, <span class="string">"new"</span>, <span class="string">"because"</span>,</div><div class="line">             <span class="string">"day"</span>, <span class="string">"more"</span>, <span class="string">"use"</span>, <span class="string">"no"</span>, <span class="string">"man"</span>, <span class="string">"find"</span>, <span class="string">"here"</span>, <span class="string">"thing"</span>, <span class="string">"give"</span>,</div><div class="line">             <span class="string">"many"</span>, <span class="string">"well"</span>]</div><div class="line"></div><div class="line">    <span class="keyword">if</span> ngram <span class="keyword">in</span> commonWords:</div><div class="line">        <span class="built_in">return</span> True</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="built_in">return</span> False</div><div class="line"></div><div class="line">def cleanInput(input):</div><div class="line">    input = re.sub(<span class="string">'\n+'</span>,<span class="string">" "</span>,input).lower() <span class="comment"># 匹配换行,用空格替换换行符</span></div><div class="line">    input = re.sub(<span class="string">'\[[0-9]*\]'</span>,<span class="string">""</span>,input) <span class="comment"># 剔除类似[1]这样的引用标记</span></div><div class="line">    input = re.sub(<span class="string">' +'</span>, <span class="string">" "</span>, input) <span class="comment">#把连续多个空格替换成一个空格</span></div><div class="line">    input = bytes(input, <span class="string">"UTF-8"</span>)</div><div class="line">    input = input.decode(<span class="string">"ascii"</span>, <span class="string">"ignore"</span>)</div><div class="line">    cleanInput = []</div><div class="line">    input = input.split(<span class="string">' '</span>)</div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> input:</div><div class="line">        item = item.strip(string.punctuation)</div><div class="line">        <span class="keyword">if</span> len(item) &gt; 1 or (item.lower() == <span class="string">'a'</span> or item.lower() == <span class="string">'i'</span>):</div><div class="line">            cleanInput.append(item)</div><div class="line">    <span class="built_in">return</span> cleanInput</div><div class="line"></div><div class="line">def ngrams(input, n):</div><div class="line">    input = cleanInput(input)</div><div class="line">    output = &#123;&#125;</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(input)-n+1):</div><div class="line">        ngramTemp =<span class="string">" "</span>.join(input[i:i+n]) <span class="comment">#这句话将n-grams拆分成n个元素组成的列表</span></div><div class="line">        <span class="keyword">if</span> isCommon(ngramTemp.split()[0]) or isCommon(ngramTemp.split()[1]):</div><div class="line">            pass</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">if</span> ngramTemp not <span class="keyword">in</span> output:</div><div class="line">                output[ngramTemp] = 0</div><div class="line">            output[ngramTemp] += 1</div><div class="line">    <span class="built_in">return</span> output</div><div class="line"></div><div class="line"><span class="comment">#获取核心词在的句子</span></div><div class="line">def getFirstSentenceCOntaining(ngram, content):</div><div class="line">    sentences = content.split(<span class="string">'.'</span>)</div><div class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences:</div><div class="line">        <span class="keyword">if</span> ngram <span class="keyword">in</span> sentence:</div><div class="line">            <span class="built_in">return</span> sentence</div><div class="line">    <span class="built_in">return</span> <span class="string">""</span></div><div class="line">content = str(urlopen(<span class="string">"http://pythonscraping.com/files/inaugurationSpeech.txt"</span>).<span class="built_in">read</span>(),<span class="string">'utf-8'</span>)</div><div class="line">ngrams = ngrams(content, 2)</div><div class="line"><span class="comment">#核心词</span></div><div class="line">sortedNGrams = sorted(ngrams.items(), key=operator.itemgetter(1), reverse=True)</div><div class="line"><span class="built_in">print</span>(sortedNGrams)</div><div class="line"><span class="comment">#核心句</span></div><div class="line"><span class="keyword">for</span> top3 <span class="keyword">in</span> range(3):</div><div class="line">    <span class="built_in">print</span>(<span class="string">"&gt;"</span>+getFirstSentenceCOntaining(sortedNGrams[top3][0],content.lower()))</div><div class="line">``` </div><div class="line">结果：</div><div class="line">&gt; the constitution of the united states is the instrument containing this grant of power to the several departments composing the government</div><div class="line"></div><div class="line">&gt; the general government has seized upon none of the reserved rights of the states</div><div class="line"></div><div class="line">&gt; such a one was afforded by the executive department constituted by the constitution</div><div class="line"></div><div class="line">我的困惑：这里返回的仅仅是匹配到的第一句话（也就是该核心词匹配的到第一句话，后面的都放弃了，是否会有不妥）</div><div class="line"></div><div class="line"><span class="comment">## 马尔可夫模型</span></div><div class="line">随机事件的特点 是一个离散事件发生之后，另一个离散事件将在前一个事件的条件下以一定的概率发生。</div><div class="line">图：马尔科夫模型描述理论天气系统</div><div class="line">• 任何一个节点引出的所有可能的总和必须等于100%。无论是多么复杂的系统，必然会 在下一步发生若干事件中的一个事件。• 虽然这个天气系统在任一时间都只有三种可能，但是你可以用这个模型生成一个天气状 态的无限次转移列表。• 只有当前节点的状态会影响后一天的状态。如果你在“晴天”节点上，即使前100天都 是晴天或雨天都没关系，明天晴天的概率还是 70%。• 有些节点可能比其他节点较难到达。这个现象的原因用数学来解释非常复杂，但是可以 直观地看出，在这个系统中任意时间节点上，第二天是“雨天”的可能性(指向它的箭 头概率之和小于“100%”)比“晴天”或“多云”要小很多</div><div class="line">``` bash </div><div class="line"><span class="comment">#生成链为100的马尔可夫链</span></div><div class="line">from urllib.request import urlopen</div><div class="line">from random import randint</div><div class="line"></div><div class="line">def wordlistSum(wordList):</div><div class="line">    sum = 0</div><div class="line">    <span class="keyword">for</span> word, value <span class="keyword">in</span> wordList.items():</div><div class="line">        sum += value</div><div class="line">    <span class="built_in">return</span> sum</div><div class="line"></div><div class="line">def retrieveRandomWord(wordlist):</div><div class="line">    randIndex = randint(1, wordlistSum(wordlist))</div><div class="line">    <span class="keyword">for</span> word, value <span class="keyword">in</span> wordlist.items():</div><div class="line">        randIndex -= value</div><div class="line">        <span class="keyword">if</span> randIndex &lt;= 0:</div><div class="line">            <span class="built_in">return</span> word</div><div class="line"></div><div class="line">def buildWordDict(text):</div><div class="line">    <span class="comment"># 剔除换行符和引号</span></div><div class="line">    text = text.replace(<span class="string">"\n"</span>, <span class="string">" "</span>)</div><div class="line">    text = text.replace(<span class="string">"\""</span>, <span class="string">""</span>)</div><div class="line">    <span class="comment"># 保证每个标点符号都和前面的单词在一起</span></div><div class="line">    <span class="comment"># 这样不会被剔除，保留在马尔可夫链中</span></div><div class="line">    punctuation = [<span class="string">','</span>, <span class="string">'.'</span>, <span class="string">';'</span>,<span class="string">':'</span>]</div><div class="line">    <span class="keyword">for</span> symbol <span class="keyword">in</span> punctuation:</div><div class="line">        text = text.replace(symbol, <span class="string">" "</span>+symbol+<span class="string">" "</span>)</div><div class="line">    words = text.split(<span class="string">" "</span>)</div><div class="line">    <span class="comment"># 过滤空单词</span></div><div class="line">    words = [word <span class="keyword">for</span> word <span class="keyword">in</span> words <span class="keyword">if</span> word != <span class="string">""</span>]</div><div class="line"></div><div class="line">    wordDict = &#123;&#125;</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(1, len(words)):</div><div class="line">        <span class="keyword">if</span> words[i-1] not <span class="keyword">in</span> wordDict: <span class="comment"># 为单词新建一个词典</span></div><div class="line">            wordDict[words[i-1]] = &#123;&#125;</div><div class="line">        <span class="keyword">if</span> words[i] not <span class="keyword">in</span> wordDict[words[i-1]]:</div><div class="line">            wordDict[words[i-1]][words[i]] = 0</div><div class="line">        wordDict[words[i-1]][words[i]] = wordDict[words[i-1]][words[i]] + 1</div><div class="line">    <span class="built_in">return</span> wordDict</div><div class="line"></div><div class="line">text = str(urlopen(<span class="string">"http://pythonscraping.com/files/inaugurationSpeech.txt"</span>)</div><div class="line">           .<span class="built_in">read</span>(), <span class="string">'utf-8'</span>)</div><div class="line">wordDict = buildWordDict(text)</div><div class="line">length = 100</div><div class="line">chain = <span class="string">""</span></div><div class="line">currentWord = <span class="string">"I"</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(0, length):</div><div class="line">    chain += currentWord+<span class="string">" "</span></div><div class="line">    currentWord = retrieveRandomWord(wordDict[currentWord])</div><div class="line"><span class="built_in">print</span>(chain)</div><div class="line">``` </div><div class="line">上述代码会随机生成一段100个单词的马尔可夫链，至于句子的含义，就是胡言乱语</div><div class="line"><span class="comment">## 维基百科六度分割：终结篇</span></div><div class="line">在寻找有向图的最短路径问题中，即找出维基百科中凯文 ·贝肯词条和其他词条之间最短链接路径的方法中，效果 最好且最常用的一种方法是广度优先搜索(breadth-first search)。</div><div class="line">``` bash </div><div class="line">from urllib.request import urlopen</div><div class="line">from bs4 import BeautifulSoup</div><div class="line">import pymysql</div><div class="line"></div><div class="line">conn = pymysql.connect(host=<span class="string">'127.0.0.1'</span>, unix_socket=<span class="string">'/tmp/mysql.sock'</span>,</div><div class="line">                       user=<span class="string">'root'</span>, passwd=<span class="string">'wyt629szk'</span>, db=<span class="string">'mysql'</span>, charset=<span class="string">'utf8'</span>)</div><div class="line">cur = conn.cursor()</div><div class="line">cur.execute(<span class="string">"USE wikipedia"</span>)</div><div class="line"></div><div class="line">class SolutionFound(RuntimeError):</div><div class="line">    def __init__(self, message):</div><div class="line">        self.message = message</div><div class="line"></div><div class="line">def getLinks(fromPageId):</div><div class="line">    cur.execute(<span class="string">"SELECT toPageId FROM links WHERE fromPageId = %s"</span>, (fromPageId))</div><div class="line">    <span class="keyword">if</span> cur.rowcount == 0:</div><div class="line">        <span class="built_in">return</span> None</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="built_in">return</span> [x[0] <span class="keyword">for</span> x <span class="keyword">in</span> cur.fetchall()]</div><div class="line"></div><div class="line">def constructDict(currentPageId):</div><div class="line">    links = getLinks(currentPageId)</div><div class="line">    <span class="keyword">if</span> links:</div><div class="line">        <span class="built_in">return</span> dict(zip(links,[&#123;&#125;]*len(links)))</div><div class="line">    <span class="built_in">return</span> &#123;&#125;</div><div class="line"></div><div class="line"><span class="comment"># 链接树要么为空，要么包含多个链接</span></div><div class="line">def searchDepth(targetPageId, currentPageId, linkTree, depth):</div><div class="line">    <span class="keyword">if</span> depth == 0:</div><div class="line">        <span class="comment">#停止递归，返回结果</span></div><div class="line">        <span class="built_in">return</span> linkTree</div><div class="line">    <span class="keyword">if</span> not linkTree:</div><div class="line">        <span class="comment">#如果函数获取的链接字典是空的，就对当前页面的链接进行搜索。如果当前页面也没链</span></div><div class="line">        <span class="comment"># 接，就返回空链接字典。</span></div><div class="line">        linkTree = constructDict(currentPageId)</div><div class="line">        <span class="keyword">if</span> not linkTree:</div><div class="line">            <span class="comment">#若此节点无连接，则跳过此节点</span></div><div class="line">            <span class="built_in">return</span> &#123;&#125;</div><div class="line">    <span class="keyword">if</span> targetPageId <span class="keyword">in</span> linkTree.keys():</div><div class="line">        <span class="built_in">print</span>(<span class="string">"TARGET"</span> + str(targetPageId) + <span class="string">" FOUND!"</span>)</div><div class="line">        raise SolutionFound(<span class="string">"PAGE: "</span>+ str(currentPageId))</div><div class="line"></div><div class="line">    <span class="keyword">for</span> branchKey, branchValue <span class="keyword">in</span> linkTree.items():</div><div class="line">        try:</div><div class="line">            <span class="comment">#递归建立链接树</span></div><div class="line">            linkTree[branchKey] = searchDepth(targetPageId, branchKey, branchValue,</div><div class="line">                                              depth-1)</div><div class="line">        except SolutionFound as e:</div><div class="line">            <span class="built_in">print</span>(e.message)</div><div class="line">            raise  SolutionFound(<span class="string">"PAGE: "</span>+str(currentPageId))</div><div class="line">    <span class="built_in">return</span> linkTree</div><div class="line">try:</div><div class="line">    searchDepth(134951, 1, &#123;&#125;, 4)</div><div class="line">    <span class="built_in">print</span>(<span class="string">"No solution found"</span>)</div><div class="line">except SolutionFound as e:</div><div class="line">    <span class="built_in">print</span>(e.message)</div></pre></td></tr></table></figure></p>
</blockquote>
</blockquote>
</blockquote>
<p>由于数据库中的数据被我删除了，所以没有测试（^~^）</p>
<h2 id="自然语言工具包（NLTK）"><a href="#自然语言工具包（NLTK）" class="headerlink" title="自然语言工具包（NLTK）"></a>自然语言工具包（NLTK）</h2><p>一个python库，用于识别和标记英语文本中各个词的词性（<a href="http://www.nltk.org/install.html）" target="_blank" rel="external">http://www.nltk.org/install.html）</a></p>
<blockquote>
<blockquote>
<blockquote>
<p>import nltk<br>nltk.download()<br>两行命令会打开NLTK的下载器</p>
</blockquote>
</blockquote>
</blockquote>
<h3 id="用NLTK做统计分析"><a href="#用NLTK做统计分析" class="headerlink" title="用NLTK做统计分析"></a>用NLTK做统计分析</h3><p>文字的单词数量，单词频率和单词词性<br>一般从Text对象开始<br>from nltk import word_tokenize<br>from nltk import Text</p>
<p>tokens = word_tokenize(“Here is some not very interesting text”)<br>text = Text(tokens)</p>
<p>NLTK库里面已经内置了几本书，可以用import函数导入：<br>from nltk.book import *</p>
<blockquote>
<blockquote>
<blockquote>
<p>len(text6)/len(words)</p>
</blockquote>
</blockquote>
</blockquote>
<p>你还可以将文本对象放到一个频率分布对象FreqDist中，查看哪些单词是最常用的，以及单词的频率是多少</p>
<blockquote>
<blockquote>
<blockquote>
<p>from nltk import FreqDist<br>fdist = FreqDist(text6)<br>fdist.most_common(10)<br>[(‘:’, 1197), (‘.’, 816), (‘!’, 801), (‘,’, 731), (“‘“, 421), (‘[‘, 3 19), (‘]’, 312), (‘the’, 299), (‘I’, 255), (‘ARTHUR’, 225)]<br>fdist[“Grail”]<br>34</p>
</blockquote>
</blockquote>
</blockquote>
<p>你可以用NLTK非常轻松的创建并搜索一个2-gram模型（还有一个trigrams 即：3-grams）：</p>
<blockquote>
<blockquote>
<blockquote>
<p>from nltk import bigrams<br>bigrams = bigrams(text6)<br>bigramsDist = FreqDist(bigrams) &gt;&gt;&gt; bigramsDist[(“Sir”, “Robin”)]<br>18</p>
</blockquote>
</blockquote>
</blockquote>
<p>对于更一般的情形，你还可以导入ngrams模块：</p>
<blockquote>
<blockquote>
<blockquote>
<p>from nltk import ngrams<br>fourgrams = ngrams(text6, 4)<br>fourgramsDist = FreqDist(fourgrams)<br>fourgramsDist[(“father”, “smelt”, “of”, “elderberries”)]<br>1</p>
</blockquote>
</blockquote>
</blockquote>
<p>频率分布，文本对象和n-gram还可以整合在一个循环中进行迭代（下面程序就是打印文本中所以以”coconut”）<br>from nltk.book import *<br>from nltk import ngrams<br>fourgrams = ngrams(text6, 4) for fourgram in fourgrams:<br>    if fourgram[0] == “coconut”:<br>        print(fourgram)</p>
<h3 id="用NLTK做词性分析"><a href="#用NLTK做词性分析" class="headerlink" title="用NLTK做词性分析"></a>用NLTK做词性分析</h3><p>考虑同一个词在不同的语境中可能会导致意思混乱<br>ex:”He was objective in achieving his objective of writing an objective philosophy, primarily using verbs in the objective case”<br>爬虫会认为（objective）被用了四次，进而简单地忽略这四个单词各自不同的含义</p>
<p>还有要分析普通英文单词组成的公司名称，或者分析某个人对一个公司的评价，像<br>ACME Products is good”和“ACME Products is not bad”意思是一样的</p>
<p>Penn Treebank语意标记</p>
<p>除了度量语言，NLTK还可以用它的超级大字典分析文本内容，帮助人们寻找单词的含义。<br>NLTK的一个基本功能就是识别句子中各个词性</p>
<blockquote>
<blockquote>
<blockquote>
<p>from nltk.book import *<br>from nltk import word_tokenize<br>text = word_tokenize(“Strange women lying in ponds distributing swords is no basis for a system of government. Supreme executive power derives from a mandate from the masses, not from some farcical aquatic ceremony.”)<br>from nltk import pos_tag<br>pos_tag(text)<br>[(‘Strange’, ‘NNP’), (‘women’, ‘NNS’), (‘lying’, ‘VBG’), (‘in’, ‘IN’)<br>, (‘ponds’, ‘NNS’), (‘distributing’, ‘VBG’), (‘swords’, ‘NNS’), (‘is’<br>, ‘VBZ’), (‘no’, ‘DT’), (‘basis’, ‘NN’), (‘for’, ‘IN’), (‘a’, ‘DT’),<br>(‘system’, ‘NN’), (‘of’, ‘IN’), (‘government’, ‘NN’), (‘.’, ‘.’),<br>(‘Supreme’, ‘NNP’), (‘executive’, ‘NN’), (‘power’, ‘NN’), (‘derives’, ‘NNS’),<br>(‘from’, ‘IN’), (‘a’, ‘DT’), (‘mandate’, ‘NN’), (‘from’, ‘IN’),<br>(‘the’, ‘DT’), (‘masses’, ‘NNS’), (‘,’, ‘,’), (‘not’, ‘RB’), (‘from’, ‘IN’),<br> (‘some’, ‘DT’), (‘farcical’, ‘JJ’), (‘aquatic’, ‘JJ’), (‘ceremony’, ‘NN’), (‘.’, ‘.’)]</p>
</blockquote>
</blockquote>
</blockquote>
<p>但是要正确的完成任务其实很复杂，用下面的例子看更直观</p>
<blockquote>
<blockquote>
<blockquote>
<p>text = word_tokenize(“The dust was thick so he had to dust”)<br>pos_tag(text)<br>[(‘The’, ‘DT’), (‘dust’, ‘NN’), (‘was’, ‘VBD’), (‘thick’, ‘JJ’), (‘so’, ‘RB’),<br>(‘he’, ‘PRP’), (‘had’, ‘VBD’), (‘to’, ‘TO’), (‘dust’, ‘VB’)]</p>
</blockquote>
</blockquote>
</blockquote>
<p>需要注意的是dust出现了两次，一个是名称，另外一个是动词（NLTK用英语的上下文无关法识别词性）</p>
<p>注：机器学习和机器训练<br>你也可以对NLTK进行训练，创建一个全新的上下文无关文法规则，比如，一种外语 的上下文无关文法规则。如果你用 Penn Treebank 词性标记手工完成了那种语言的大部 分文本的语义标记，那么你就可以把结果传给NLTK，然后训练它对其他未标记的文 本进行语义标记</p>
<h4 id="示例（找出google作为名称而不是动词的句子）"><a href="#示例（找出google作为名称而不是动词的句子）" class="headerlink" title="示例（找出google作为名称而不是动词的句子）"></a>示例（找出google作为名称而不是动词的句子）</h4><p>``` bash<br>from nltk import word_tokenize, sent_tokenize, pos_tag<br>sentences = sent_tokenize(“Google is one of the best companies in the world. I constantly google myself to see what I’m up to.”)<br>nouns = [‘NN’, ‘NNS’, ‘NNP’, ‘NNPS’]<br>for sentence in sentences:<br>    if “google” in sentence.lower():<br>        taggedWords = pos_tag(word_tokenize(sentence))<br>            for word in taggleWords:<br>                if word[0].lower() == “google” and word[1] in nouns:                         print(sentence)</p>
<h3 id="其他资源"><a href="#其他资源" class="headerlink" title="其他资源"></a>其他资源</h3><p>Natural Language Processing with Python(http:// shop.oreilly.com/product/9780596516499.do)<br>Natural Language Annotation for Machine Learning(<a href="http://shop.oreilly.com/product/0636920020578.do" target="_blank" rel="external">http://shop.oreilly.com/product/0636920020578.do</a>)</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/04/自然语言处理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="EtanWatson">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EWSUN">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/04/自然语言处理/" itemprop="url">自然语言处理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-04T11:07:53+08:00">
                2017-10-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/03/python数据收集（数据清洗）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="EtanWatson">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EWSUN">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/03/python数据收集（数据清洗）/" itemprop="url">python数据收集（数据清洗）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-03T20:51:22+08:00">
                2017-10-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python数据收集/" itemprop="url" rel="index">
                    <span itemprop="name">python数据收集</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h1><h2 id="编写代码清洗数据"><a href="#编写代码清洗数据" class="headerlink" title="编写代码清洗数据"></a>编写代码清洗数据</h2><p>n-gram<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">from urllib.request import urlopen</div><div class="line">from bs4 import BeautifulSoup</div><div class="line">import re</div><div class="line"></div><div class="line"><span class="comment">#清洗规则函数</span></div><div class="line"></div><div class="line"><span class="comment">#剔除单字符的“单词”，除非这个字符是“i”或“a”;</span></div><div class="line"><span class="comment">#剔除维基百科的引用标记(方括号包裹的数字，如[1]);</span></div><div class="line"><span class="comment">#剔除标点符号(注意:这个规则有点儿矫枉过正，在第9章我们将详细介绍，本例暂时这样处理)。</span></div><div class="line">import string</div><div class="line"></div><div class="line">def cleanInput(input):</div><div class="line">    input = re.sub(<span class="string">'\n+'</span>,<span class="string">' '</span>, input)</div><div class="line">    input = re.sub(<span class="string">'\[[0-9]*\]'</span>,<span class="string">""</span>, input)</div><div class="line">    input = re.sub(<span class="string">' +'</span>,<span class="string">" "</span>, input)</div><div class="line">    input = bytes(input,<span class="string">"UTF-8"</span>)</div><div class="line">    input = input.decode(<span class="string">"ascii"</span>, <span class="string">"ignore"</span>)</div><div class="line">    cleanInput = []</div><div class="line">    input = input.split(<span class="string">' '</span>)</div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> input:</div><div class="line">        item = item.strip(string.punctuation)</div><div class="line">        <span class="keyword">if</span> len(item) &gt; 1 or (item.lower() == <span class="string">'i'</span>):</div><div class="line">            cleanInput.append(item)</div><div class="line">    <span class="built_in">return</span> cleanInput</div><div class="line"></div><div class="line">def ngrams(input, n):</div><div class="line">    input = input.upper()</div><div class="line">    input = cleanInput(input)</div><div class="line">    output = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(input)-n+1):</div><div class="line">        output.append(input[i:i+n])</div><div class="line">    <span class="built_in">return</span> output</div><div class="line">html = urlopen(<span class="string">"http://en.wikipedia.org/wiki/Python_(programming_language)"</span>)</div><div class="line">bsObj = BeautifulSoup(html,<span class="string">'html.parser'</span>)</div><div class="line">content = bsObj.find(<span class="string">'div'</span>,&#123;<span class="string">'id'</span>:<span class="string">'mw-content-text'</span>&#125;).get_text()</div><div class="line">ngrams = ngrams(content, 2)</div><div class="line"><span class="built_in">print</span>(ngrams)</div><div class="line"><span class="built_in">print</span>(<span class="string">"2-grams count is: "</span>+str(len(ngrams)))</div></pre></td></tr></table></figure></p>
<blockquote>
<blockquote>
<blockquote>
<p>import string<br>print(string.punctuation)<br>!”#$%&amp;’()*+,-./:;&lt;=&gt;?@[]^_`{|}~</p>
<h3 id="数据标准化"><a href="#数据标准化" class="headerlink" title="数据标准化"></a>数据标准化</h3><p>python的字典是无序的，不能想数组一样直接对n-gran序列频率进行排序，字典内部的元素位置排序以后再次使用时还是<br>会变化，在python的collections库里面有一个OrderedDict可以解决这个问题</p>
<pre><code class="bash">from collection import OrderedDict
……
ngrams = OrderedDict(sorted(ngrams.items(), key=lambda t: t[1), reverse=True)
</code></pre>
<p>没有跑起来，网速不好（下次测试）</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="数据存储后在清洗"><a href="#数据存储后在清洗" class="headerlink" title="数据存储后在清洗"></a>数据存储后在清洗</h2><p>OpenRefine</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/03/python数据收集（六）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="EtanWatson">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EWSUN">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/03/python数据收集（六）/" itemprop="url">python数据收集（六）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-03T15:36:23+08:00">
                2017-10-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python数据收集/" itemprop="url" rel="index">
                    <span itemprop="name">python数据收集</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="读取文档"><a href="#读取文档" class="headerlink" title="读取文档"></a>读取文档</h1><h2 id="文档编码"><a href="#文档编码" class="headerlink" title="文档编码"></a>文档编码</h2><p>纯文本文件，视频文件和图像文件的唯一区别，就是它们的0和1面向用户的转换方式不同</p>
<h3 id="纯文本"><a href="#纯文本" class="headerlink" title="纯文本"></a>纯文本</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">from urllib.request import urlopen</div><div class="line">textPage = urlopen(<span class="string">"http://www.pythonscraping.com/pages/warandpeace/chapter1.txt"</span>)</div><div class="line"><span class="built_in">print</span>(textPage.read())</div></pre></td></tr></table></figure>
<p>像这种纯文本的，使用BeautifulSoup库就没有用了，如果变成BeautifulSoup反而适得其反</p>
<h2 id="文本编码和全球互联网"><a href="#文本编码和全球互联网" class="headerlink" title="文本编码和全球互联网"></a>文本编码和全球互联网</h2><p>UTF-8:<br>在 UTF-8 设计过程中，设计师决定利用 ASCII 文档里的“填充位”，让所有以“0”开头的 字节表示这个字符只用 1 个字节，从而把 ASCII 和 UTF-8 编码完美地结合在一起。因此， 下面的字符在 ASCII 和 UTF-8 两种编码方式中都是有效的:<br>      01000001 - A<br>      01000010 - B<br>      01000011 - C<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"># from urllib.request import urlopen</div><div class="line"># textPage = urlopen(&quot;http://www.pythonscraping.com/pages/warandpeace/chapter1.txt&quot;)</div><div class="line"># print(textPage.read())</div><div class="line"></div><div class="line"></div><div class="line"># from urllib.request import urlopen</div><div class="line"># textPage = urlopen(&quot;http://www.pythonscraping.com/pages/warandpeace/chapter1-ru.txt&quot;)</div><div class="line"># print(str(textPage.read(),&apos;utf-8&apos;))</div><div class="line"></div><div class="line">#用BeautifulSoup和python3.x对文档进行UTF-8编码，如下所示</div><div class="line">from urllib.request import urlopen</div><div class="line">from bs4 import BeautifulSoup</div><div class="line">html = urlopen(&quot;http://en.wikipedia.org/wiki/Python_(programming_language)&quot;)</div><div class="line">bsObj = BeautifulSoup(html)</div><div class="line">content = bsObj.find(&quot;div&quot;, &#123;&quot;id&quot;:&quot;mw-content-text&quot;&#125;).get_text()</div><div class="line">content = bytes(content, &quot;UTF-8&quot;)</div><div class="line">content = content.decode(&quot;UTF-8&quot;)</div></pre></td></tr></table></figure></p>
<h2 id="CSV"><a href="#CSV" class="headerlink" title="CSV"></a>CSV</h2><h3 id="读取CSV文件"><a href="#读取CSV文件" class="headerlink" title="读取CSV文件"></a>读取CSV文件</h3><p>• 手动把CSV文件下载到本机，然后用Python定位文件位置;<br>• 写Python程序下载文件，读取之后再把源文件删除;<br>• 从网上直接把文件读成一个字符串，然后转换成一个StringIO对象，使它具有文件的<br>属性。（这个方法比较可行）</p>
<h2 id="PDF"><a href="#PDF" class="headerlink" title="PDF"></a>PDF</h2><p>pdf转字符串(直接上代码)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#把PDF 读成字符串，然后用 StringIO 转换成文件对象</span></div><div class="line">from urllib.request import urlopen</div><div class="line">from pdfminer.pdfinterp import PDFResourceManager, process_pdf</div><div class="line">from pdfminer.converter import TextConverter</div><div class="line">from pdfminer.layout import LAParams</div><div class="line">from io import StringIO</div><div class="line">from io import open</div><div class="line"></div><div class="line">def readPDF(pdfFile):</div><div class="line">    rsrcmgr = PDFResourceManager()</div><div class="line">    retstr = StringIO()</div><div class="line">    laparams = LAParams()</div><div class="line">    device = TextConverter(rsrcmgr, retstr, laparams=laparams)</div><div class="line">    process_pdf(rsrcmgr, device, pdfFile)</div><div class="line">    device.close()</div><div class="line">    content = retstr.getvalue()</div><div class="line">    retstr.close()</div><div class="line">    <span class="built_in">return</span> content</div><div class="line">pdfFile = urlopen(<span class="string">"http://pythonscraping.com/pages/warandpeace/chapter1.pdf"</span>)</div><div class="line">outputString = readPDF(pdfFile)</div><div class="line"><span class="built_in">print</span>(outputString)</div><div class="line">pdfFile.close()</div><div class="line">``` </div><div class="line"><span class="comment">#如果格式里面有图片，各式各样的文本格式，或者带有表格和数据图的时候，输出结果可能不是很完美</span></div><div class="line"></div><div class="line"><span class="comment">## 微软Word和.docx</span></div><div class="line"><span class="comment">### 读取Microsoft Office 文件</span></div><div class="line">第一步是从文件读取XML</div><div class="line">``` bash </div><div class="line">from zipfile import ZipFile</div><div class="line">from urllib.request import urlopen</div><div class="line">from io import BytesIO</div><div class="line">from bs4 import BeautifulSoup</div><div class="line"></div><div class="line">wordFile = urlopen(<span class="string">"http://pythonscraping.com/pages/AWordDocument.docx"</span>).<span class="built_in">read</span>()</div><div class="line">wordFile = BytesIO(wordFile)</div><div class="line">document = ZipFile(wordFile)</div><div class="line">xml_content = document.read(<span class="string">'word/document.xml'</span>)</div><div class="line"></div><div class="line">wordObj = BeautifulSoup(xml_content.decode(<span class="string">'utf-8'</span>),<span class="string">'html.parser'</span>)</div><div class="line"><span class="comment"># textStrings = wordObj.findAll("w:t")</span></div><div class="line"><span class="comment"># for textElem in textStrings:</span></div><div class="line"><span class="comment">#     print(textElem.text)</span></div><div class="line"><span class="comment">#print(wordObj.text)</span></div><div class="line">textStrings = wordObj.findAll(<span class="string">"w:t"</span>)</div><div class="line"><span class="keyword">for</span> textElem <span class="keyword">in</span> textStrings:</div><div class="line">    closeTag = <span class="string">""</span></div><div class="line">    try:</div><div class="line">        style = textElem.parent.previousSibling.find(<span class="string">"w:pstyle"</span>)</div><div class="line">        <span class="keyword">if</span> style is not None and style[<span class="string">"w:val"</span>] == <span class="string">"Title"</span>: <span class="built_in">print</span>(<span class="string">"&lt;h1&gt;"</span>)</div><div class="line">        closeTag = <span class="string">"&lt;/h1&gt;"</span></div><div class="line">    except AttributeError: <span class="comment">#不打印标签</span></div><div class="line">        pass</div><div class="line">        <span class="built_in">print</span>(textElem.text)</div><div class="line">        <span class="built_in">print</span>(closeTag)</div></pre></td></tr></table></figure></p>
<p>由于按照书上的做法是得到的是一个空的textStrings,但是可用wordObj.text属性找出，但是格式不太对</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/03/读取文档/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="EtanWatson">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EWSUN">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/03/读取文档/" itemprop="url">读取文档</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-03T15:35:49+08:00">
                2017-10-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/02/python数据收集（五）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="EtanWatson">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EWSUN">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/02/python数据收集（五）/" itemprop="url">python数据收集（五）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-02T15:56:58+08:00">
                2017-10-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python数据收集/" itemprop="url" rel="index">
                    <span itemprop="name">python数据收集</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="存储数据"><a href="#存储数据" class="headerlink" title="存储数据"></a>存储数据</h1><h2 id="媒体文件"><a href="#媒体文件" class="headerlink" title="媒体文件"></a>媒体文件</h2><h3 id="盗链"><a href="#盗链" class="headerlink" title="盗链"></a>盗链</h3><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><h4 id="下载单个图片"><a href="#下载单个图片" class="headerlink" title="下载单个图片"></a>下载单个图片</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">from urllib.request import urlretrieve </div><div class="line">from urllib.request import urlopen </div><div class="line">from bs4 import BeautifulSouphtml = urlopen(<span class="string">"http://www.pythonscraping.com"</span>)bsObj = BeautifulSoup(html)imageLocation = bsObj.find(<span class="string">"a"</span>, &#123;<span class="string">"id"</span>: <span class="string">"logo"</span>&#125;).find(<span class="string">"img"</span>)[<span class="string">"src"</span>]urlretrieve (imageLocation, <span class="string">"logo.jpg"</span>)</div><div class="line">注：</div><div class="line">open newline可选参数：None，’’，\n，\r，\r\n</div></pre></td></tr></table></figure>
<h4 id="下载src下的所有资源（该页面）"><a href="#下载src下的所有资源（该页面）" class="headerlink" title="下载src下的所有资源（该页面）"></a>下载src下的所有资源（该页面）</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#将 http://pythonscraping. com 主页上的所有src属性的文件下载下来</span></div><div class="line">import os</div><div class="line">from urllib.request import urlretrieve</div><div class="line">from urllib.request import urlopen</div><div class="line">from  bs4 import BeautifulSoup</div><div class="line"></div><div class="line">downloadDirectory = <span class="string">"downloaded"</span></div><div class="line">baseUrl = <span class="string">"http://pythonscraping.com"</span></div><div class="line"></div><div class="line">def getAbsoluteURL(baseUrl, <span class="built_in">source</span>):</div><div class="line">    <span class="keyword">if</span> source.startswith(<span class="string">"http://www."</span>):</div><div class="line">        url = <span class="string">"http://"</span>+<span class="built_in">source</span>[11:]</div><div class="line">    <span class="keyword">elif</span> source.startswith(<span class="string">"http://"</span>):</div><div class="line">        url = <span class="built_in">source</span></div><div class="line">    <span class="keyword">elif</span> source.startswith(<span class="string">"www."</span>):</div><div class="line">        url = <span class="built_in">source</span>[4:]</div><div class="line">        url = <span class="string">"http://"</span> + <span class="built_in">source</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        url = baseUrl+<span class="string">"/"</span>+<span class="built_in">source</span></div><div class="line">    <span class="keyword">if</span> baseUrl not <span class="keyword">in</span> url:</div><div class="line">        <span class="built_in">return</span> None</div><div class="line">    <span class="built_in">return</span> url</div><div class="line"></div><div class="line">def getDownloadPath(baseUrl, absoluteUrl, downloadDirectory):</div><div class="line">    path = absoluteUrl.replace(<span class="string">"www."</span>,<span class="string">""</span>)</div><div class="line">    path = path.replace(baseUrl,<span class="string">""</span>)</div><div class="line">    path = downloadDirectory + path</div><div class="line">    directory = os.path.dirname(path)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> not os.path.exists(directory):</div><div class="line">        os.makedirs(directory)</div><div class="line">    <span class="built_in">return</span> path</div><div class="line"></div><div class="line">html = urlopen(<span class="string">"http://www.pythonscraping.com"</span>)</div><div class="line">bsObj = BeautifulSoup(html,<span class="string">'html.parser'</span>)</div><div class="line">downloadList = bsObj.findAll(src = True)</div><div class="line"></div><div class="line"><span class="keyword">for</span> download <span class="keyword">in</span> downloadList:</div><div class="line">    fileUrl = getAbsoluteURL(baseUrl, download[<span class="string">"src"</span>])</div><div class="line">    <span class="keyword">if</span> fileUrl is not None:</div><div class="line">        <span class="built_in">print</span>(fileUrl)</div><div class="line">        urlretrieve(fileUrl,getDownloadPath(baseUrl, fileUrl, downloadDirectory))</div></pre></td></tr></table></figure>
<h4 id="保存为CSV格式"><a href="#保存为CSV格式" class="headerlink" title="保存为CSV格式"></a>保存为CSV格式</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#将 http://pythonscraping. com 主页上的所有src属性的文件下载下来</span></div><div class="line">import os</div><div class="line">from urllib.request import urlretrieve</div><div class="line">from urllib.request import urlopen</div><div class="line">from  bs4 import BeautifulSoup</div><div class="line"></div><div class="line">downloadDirectory = <span class="string">"downloaded"</span></div><div class="line">baseUrl = <span class="string">"http://pythonscraping.com"</span></div><div class="line"></div><div class="line">def getAbsoluteURL(baseUrl, <span class="built_in">source</span>):</div><div class="line">    <span class="keyword">if</span> source.startswith(<span class="string">"http://www."</span>):</div><div class="line">        url = <span class="string">"http://"</span>+<span class="built_in">source</span>[11:]</div><div class="line">    <span class="keyword">elif</span> source.startswith(<span class="string">"http://"</span>):</div><div class="line">        url = <span class="built_in">source</span></div><div class="line">    <span class="keyword">elif</span> source.startswith(<span class="string">"www."</span>):</div><div class="line">        url = <span class="built_in">source</span>[4:]</div><div class="line">        url = <span class="string">"http://"</span> + <span class="built_in">source</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        url = baseUrl+<span class="string">"/"</span>+<span class="built_in">source</span></div><div class="line">    <span class="keyword">if</span> baseUrl not <span class="keyword">in</span> url:</div><div class="line">        <span class="built_in">return</span> None</div><div class="line">    <span class="built_in">return</span> url</div><div class="line"></div><div class="line">def getDownloadPath(baseUrl, absoluteUrl, downloadDirectory):</div><div class="line">    path = absoluteUrl.replace(<span class="string">"www."</span>,<span class="string">""</span>)</div><div class="line">    path = path.replace(baseUrl,<span class="string">""</span>)</div><div class="line">    path = downloadDirectory + path</div><div class="line">    directory = os.path.dirname(path)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> not os.path.exists(directory):</div><div class="line">        os.makedirs(directory)</div><div class="line">    <span class="built_in">return</span> path</div><div class="line"></div><div class="line">html = urlopen(<span class="string">"http://www.pythonscraping.com"</span>)</div><div class="line">bsObj = BeautifulSoup(html,<span class="string">'html.parser'</span>)</div><div class="line">downloadList = bsObj.findAll(src = True)</div><div class="line"></div><div class="line"><span class="keyword">for</span> download <span class="keyword">in</span> downloadList:</div><div class="line">    fileUrl = getAbsoluteURL(baseUrl, download[<span class="string">"src"</span>])</div><div class="line">    <span class="keyword">if</span> fileUrl is not None:</div><div class="line">        <span class="built_in">print</span>(fileUrl)</div><div class="line">        urlretrieve(fileUrl,getDownloadPath(baseUrl, fileUrl, downloadDirectory))</div></pre></td></tr></table></figure>
<h2 id="MySql"><a href="#MySql" class="headerlink" title="MySql"></a>MySql</h2><p>之前安装好了mysql，但是今天从终端连接的时候 mysql -u root -p居然报错了（心中有一万个草泥马飞过）<br>俺是文明人，错误代码忘记截图了，忽略以上信息<br>du -sh *<br>lsof -i:3306<br>ps -A|grep mysql<br>查看MySQL的默认日志文件的位置<br>show variables like ‘general_log_file’;</p>
<p>#我的默认位置<br>/usr/local/mysql-5.7.19-macos10.12-x86_64/data/<strong>*</strong>MacBook-Air.log</p>
<h3 id="与python整合"><a href="#与python整合" class="headerlink" title="与python整合"></a>与python整合</h3><p>开源库 PyMySQL<br>OK 默认你的数据库中已经有一张pages的表<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">import pymysql</div><div class="line">conn = pymysql.connect(host=<span class="string">'127.0.0.1'</span>, unix_socket=<span class="string">'/tmp/mysql.sock'</span>,</div><div class="line">                       user=<span class="string">'root'</span>,passwd=‘******’, db=<span class="string">'mysql'</span>)</div><div class="line">cur = conn.cursor()</div><div class="line">cur.execute(<span class="string">"USE scraping"</span>)</div><div class="line"></div><div class="line">cur.execute(<span class="string">"SELECT * FROM pages WHERE id = 1"</span>)</div><div class="line"><span class="built_in">print</span>(cur.fetchone())</div><div class="line">cur.close()</div><div class="line">conn.close()</div></pre></td></tr></table></figure></p>
<p>测试数据库是否能正常连接，以及从数据库中读取数据</p>
<h4 id="连接-光标模式"><a href="#连接-光标模式" class="headerlink" title="连接/光标模式"></a>连接/光标模式</h4><p>连接模式除了要链接数据库外，还要发送数据库信息，处理回滚操作，创建新的光标对象等等<br>注意：用完光标和链接后，如果不关闭就会导致连接泄露，造成一种为未关闭连接的现象，这种现象会一直想好数据库资源<br>所以用完数据库之后记得关闭连接</p>
<h4 id="设置数据库字符"><a href="#设置数据库字符" class="headerlink" title="设置数据库字符"></a>设置数据库字符</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ALTER DATABASE scraping CHARACTER SET = utf8mb4 COLLATE = utf8mb4_unicode_ci; </div><div class="line">ALTER TABLE pages CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; </div><div class="line">ALTER TABLE pages CHANGE title title VARCHAR(200) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;ALTER TABLE pages CHANGE content content VARCHAR(10000) CHARACTER SET utf8mb4 CO LLATE utf8mb4_unicode_ci;</div></pre></td></tr></table></figure>
<p>虽然不晓得utf8mb4与utf8mb4_unicode_ci有什么区别，但是还是设置了（好像这是一种东西，使用COLLATE不同）<br>不过要比utf-8要多一个位元</p>
<h4 id="将网页上爬取的信息插入到数据库中"><a href="#将网页上爬取的信息插入到数据库中" class="headerlink" title="将网页上爬取的信息插入到数据库中"></a>将网页上爬取的信息插入到数据库中</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">from urllib.request import urlopen</div><div class="line">from bs4 import BeautifulSoup</div><div class="line">import re</div><div class="line">import datetime</div><div class="line">import random</div><div class="line">import pymysql</div><div class="line"></div><div class="line">conn = pymysql.connect(host=<span class="string">'127.0.0.1'</span>, unix_socket=<span class="string">'/tmp/mysql.sock'</span>,</div><div class="line">                       user=<span class="string">'root'</span>,passwd=<span class="string">'wyt629szk'</span>, db=<span class="string">'mysql'</span>, charset=<span class="string">'utf-8'</span>)</div><div class="line">cur = conn.cursor()</div><div class="line">cur.execute(<span class="string">"USE scraping"</span>)</div><div class="line"></div><div class="line">random.seed(datetime.datetime.now())</div><div class="line"></div><div class="line">def store(title, content):</div><div class="line">    cur.execute(<span class="string">"INSERT INTO pages(title, content) VALUES (\"%s\",\"%s\"),(title. content)"</span>)</div><div class="line">    cur.connection.commit()</div><div class="line"></div><div class="line">def getLinks(articleUrl):</div><div class="line">    html = urlopen(<span class="string">"http://en.wikipedia.org"</span>+articleUrl)</div><div class="line">    bsObj = BeautifulSoup(html)</div><div class="line">    title = bsObj.find(<span class="string">"h1"</span>).get_text()</div><div class="line">    content = bsObj.find(<span class="string">"div"</span>,&#123;<span class="string">"id"</span>:<span class="string">"mw-content-text"</span>&#125;).find(<span class="string">"p"</span>).get_text()</div><div class="line">    store(title, content)</div><div class="line">    <span class="built_in">return</span> bsObj.find(<span class="string">"div"</span>,&#123;<span class="string">"id"</span>:<span class="string">"bodyContent"</span>&#125;).findAll(<span class="string">"a"</span>,href=re.compile(<span class="string">"^(/wiki/)((?!:).)*$"</span>))</div><div class="line"></div><div class="line">links = getLinks(<span class="string">"/wiki/Kevin_Bacon"</span>)</div><div class="line">try:</div><div class="line">    <span class="keyword">while</span> len(links) &gt; 0:</div><div class="line">        newArticle = links[random.randint(0, len(links)-1)].attrs[<span class="string">'href'</span>]</div><div class="line">        <span class="built_in">print</span>(newArticle)</div><div class="line">        links = getLinks(newArticle)</div><div class="line">finally:</div><div class="line">    cur.close()</div><div class="line">    conn.close()</div></pre></td></tr></table></figure>
<h3 id="数据库技术与最佳实践"><a href="#数据库技术与最佳实践" class="headerlink" title="数据库技术与最佳实践"></a>数据库技术与最佳实践</h3><h4 id="主动创建一个id字段"><a href="#主动创建一个id字段" class="headerlink" title="主动创建一个id字段"></a>主动创建一个id字段</h4><h4 id="用智能索引"><a href="#用智能索引" class="headerlink" title="用智能索引"></a>用智能索引</h4><p>额外的索引血药占用更多的空间，而且插入新行的时候也需要花费更多的时间<br>例如：如果你经常要查询一个字段<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&gt;SELECT * FROM dictionary WHERE definition=<span class="string">"A small furry animal that says meow"</span>;</div><div class="line"><span class="comment">#你可以给definition建立一个该字段前16个字符的智能索引</span></div><div class="line">CREATE INDEX definition ON dictionary (id, definition(16));</div></pre></td></tr></table></figure></p>
<h4 id="数据查询时间和数据库空间的问题"><a href="#数据查询时间和数据库空间的问题" class="headerlink" title="数据查询时间和数据库空间的问题"></a>数据查询时间和数据库空间的问题</h4><p>拆表 -&gt; 可以去除冗余</p>
<h3 id="MySQL里的”六度空间游戏”"><a href="#MySQL里的”六度空间游戏”" class="headerlink" title="MySQL里的”六度空间游戏”"></a>MySQL里的”六度空间游戏”</h3><p>设计一个带有两张表的数据库来分别存储页面和链接，两张表都带有创建时间和独立的ID号，代码如下所示:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">CREATE TABLE `wikipedia`.`pages` (`id` INT NOT NULL AUTO_INCREMENT,`url` VARCHAR(255) NOT NULL,`created` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`));</div><div class="line"></div><div class="line">CREATE TABLE `wikipedia`.`links` ( `id` INT NOT NULL AUTO_INCREMENT, `fromPageId` INT NULL, `toPageId` INT NULL,`created` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`));</div></pre></td></tr></table></figure></p>
<p>注：因为页面标题要在你进入页面后读取内容才能抓到。那么如果我们想创建一个高效的爬虫来填充这些数据表，那么只存储页的<br>链接就可以保存词条页面了，甚至不需要访问词条页面（不是很懂）</p>
<h2 id="Email（代码没有跑通，Connection-refused，先把书上的源码贴上来）"><a href="#Email（代码没有跑通，Connection-refused，先把书上的源码贴上来）" class="headerlink" title="Email（代码没有跑通，Connection refused，先把书上的源码贴上来）"></a>Email（代码没有跑通，Connection refused，先把书上的源码贴上来）</h2><pre><code class="bash">import smtplib
from email.mime.text import MIMEText
from bs4 import BeautifulSoup
from urllib.request import urlopen
import time

def sendMail(subject, body):
    msg = MIMEText(body)
    msg[<span class="string">'Subject'</span>] = subject
    msg[<span class="string">'From'</span>] = <span class="string">"christmas_alerts@pythonscraping.com"</span>
    msg[<span class="string">'To'</span>] = <span class="string">"ryan@pythonscraping.com"</span>
    s = smtplib.SMTP(<span class="string">'localhost'</span>)
    s.send_message(msg)
    s.quit()

bsObj = BeautifulSoup(urlopen(<span class="string">"https://isitchristmas.com/"</span>))
<span class="keyword">while</span>(bsObj.find(<span class="string">"a"</span>, {<span class="string">"id"</span>:<span class="string">"answer"</span>}).attrs[<span class="string">'title'</span>] == <span class="string">"NO"</span>):
    <span class="built_in">print</span>(<span class="string">"It is not Christmas yet."</span>)
    time.sleep(3600)
    bsObj = BeautifulSoup(urlopen(<span class="string">"https://isitchristmas.com/"</span>))
    sendMail(<span class="string">"It's Christmas!"</span>,
              <span class="string">"According to http://itischristmas.com, it is Christmas!"</span>)
</code></pre>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          
            <img class="site-author-image" itemprop="image"
              src="/images/header.png"
              alt="EtanWatson" />
          
            <p class="site-author-name" itemprop="name">EtanWatson</p>
            <p class="site-description motion-element" itemprop="description">有所舍，有所爱，做一个感性的码农</p>
        </div>

        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
            
              <a href="/archives/">
            
                <span class="site-state-item-count">53</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">15</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">15</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">EtanWatson</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动</div>

  <span class="post-meta-divider">|</span>

  <div class="theme-info">主题 &mdash; <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.2</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>


  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  








  





  

  

  

  

  

  

</body>
</html>
